 a02_make_qa.py ä¸¦åˆ—åŒ–ææ¡ˆã¨Todoãƒªã‚¹ãƒˆ

  ğŸ“‹ ç¾çŠ¶åˆ†æã¨ãƒœãƒˆãƒ«ãƒãƒƒã‚¯

  ç¾åœ¨ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼:
  1. é€æ¬¡å‡¦ç†: å„ãƒãƒ£ãƒ³ã‚¯ã‚’é †ç•ªã«å‡¦ç†ï¼ˆgenerate_qa_pairs_for_chunkï¼‰
  2. ãƒãƒƒãƒå‡¦ç†: è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã¾ã¨ã‚ã¦å‡¦ç†ï¼ˆgenerate_qa_pairs_for_batchï¼‰
  3. APIå‘¼ã³å‡ºã—: OpenAI API (client.responses.parse)ãŒä¸»ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯
  4. å‡¦ç†æ™‚é–“: 90åˆ†ä»¥ä¸Šï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†æ™‚ï¼‰

  ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç®‡æ‰€:
  - 884-889è¡Œç›®: client.responses.parse() - åŒæœŸçš„APIå‘¼ã³å‡ºã—
  - å„ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ãŒç›´åˆ—å®Ÿè¡Œ

  ğŸš€ Celeryã‚’ä½¿ã£ãŸä¸¦åˆ—åŒ–ææ¡ˆ

  1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

  [ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹] â†’ [Redis/RabbitMQ] â†’ [Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ç¾¤]
                           â†“
                     [ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼]
                           â†“
                [ä¸¦åˆ—OpenAI APIå‘¼ã³å‡ºã—]

  2. ä¸¦åˆ—åŒ–å¯èƒ½ãªå‡¦ç†å˜ä½

  | ãƒ¬ãƒ™ãƒ«     | å¯¾è±¡é–¢æ•°/ã‚¯ãƒ©ã‚¹                    | ä¸¦åˆ—åŒ–æ–¹æ³•                    |
  |---------|-----------------------------|--------------------------|
  | ãƒãƒ£ãƒ³ã‚¯ãƒ¬ãƒ™ãƒ« | generate_qa_pairs_for_chunk | å„ãƒãƒ£ãƒ³ã‚¯ã‚’ç‹¬ç«‹ã—ãŸCeleryã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œ |
  | ãƒãƒƒãƒãƒ¬ãƒ™ãƒ«  | generate_qa_pairs_for_batch | ãƒãƒƒãƒå†…ã®å„ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—å‡¦ç†          |
  | æ–‡æ›¸ãƒ¬ãƒ™ãƒ«   | generate_qa_for_dataset     | è¤‡æ•°æ–‡æ›¸ã‚’åŒæ™‚å‡¦ç†                |

  3. Celeryã‚¿ã‚¹ã‚¯è¨­è¨ˆ

  # celery_tasks.pyï¼ˆæ–°è¦ä½œæˆï¼‰
  @celery_app.task(bind=True, max_retries=3)
  def process_chunk_task(self, chunk_data, config, model):
      """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®Q/Aç”Ÿæˆã‚¿ã‚¹ã‚¯"""

  @celery_app.task
  def process_batch_task(chunks_batch, config, model):
      """ãƒãƒƒãƒå‡¦ç†ã‚¿ã‚¹ã‚¯"""

  @celery_app.task
  def aggregate_results_task(qa_pairs_list):
      """çµæœé›†ç´„ã‚¿ã‚¹ã‚¯"""

  4. å®Ÿè£…æ™‚ã®è€ƒæ…®äº‹é …

  | é …ç›®        | æ¨å¥¨è¨­å®š    | ç†ç”±                 |
  |-----------|---------|--------------------|
  | ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°     | 5-10    | OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…® |
  | åŒæ™‚å®Ÿè¡Œæ•°     | 5       | APIåˆ¶é™ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹     |
  | ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | 300ç§’    | é•·æ™‚é–“å‡¦ç†ã®é˜²æ­¢           |
  | ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥    | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• | APIã‚¨ãƒ©ãƒ¼å¯¾ç­–           |
  | ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°    | Redisæ¨å¥¨ | é«˜é€Ÿãƒ»ã‚·ãƒ³ãƒ—ãƒ«            |

  5. ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

  # OpenAI APIåˆ¶é™å¯¾å¿œ
  RATE_LIMITS = {
      "gpt-5-mini": {
          "rpm": 3500,  # Requests Per Minute
          "tpm": 200000  # Tokens Per Minute
      }
  }

  # Celeryã§ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…
  @celery_app.task(rate_limit='50/m')  # åˆ†ã‚ãŸã‚Š50ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åˆ¶é™

  6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

  # ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
  retry_kwargs = {
      'max_retries': 3,
      'countdown': 60,  # 60ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤
      'retry_jitter': True,
      'retry_backoff': True,
      'retry_backoff_max': 600  # æœ€å¤§10åˆ†
  }

  7. é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

  | ãƒ„ãƒ¼ãƒ«        | ç”¨é€”            |
  |------------|---------------|
  | Flower     | Celeryã‚¿ã‚¹ã‚¯ã®å¯è¦–åŒ– |
  | Prometheus | ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†       |
  | ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚°     | é€²æ—ç‡ãƒ»æ®‹ã‚Šæ™‚é–“è¡¨ç¤º    |

  ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

  | æŒ‡æ¨™     | ç¾çŠ¶      | ç›®æ¨™         | æ”¹å–„ç‡      |
  |--------|---------|------------|----------|
  | å‡¦ç†æ™‚é–“   | 90åˆ†ä»¥ä¸Š   | 15-20åˆ†     | 75-80%å‰Šæ¸› |
  | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ | 1ãƒãƒ£ãƒ³ã‚¯/ç§’ | 5-10ãƒãƒ£ãƒ³ã‚¯/ç§’ | 5-10å€    |
  | CPUä½¿ç”¨ç‡ | 10-20%  | 60-80%     | åŠ¹ç‡å‘ä¸Š     |

  ğŸ”§ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

  1. ç’°å¢ƒæº–å‚™
    - Celery, Redis ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    - celery_config.py ä½œæˆ
  2. ã‚¿ã‚¹ã‚¯åˆ†é›¢
    - generate_qa_pairs_for_chunk ã‚’Celeryã‚¿ã‚¹ã‚¯ã«å¤‰æ›
    - ãƒãƒƒãƒå‡¦ç†ã®ä¸¦åˆ—åŒ–å®Ÿè£…
  3. ã‚­ãƒ¥ãƒ¼ç®¡ç†
    - å„ªå…ˆåº¦ä»˜ãã‚­ãƒ¥ãƒ¼è¨­å®š
    - ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼å®Ÿè£…
  4. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
    - Flowerè¨­å®š
    - ãƒ­ã‚°é›†ç´„ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
  5. ãƒ†ã‚¹ãƒˆ
    - å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®å‹•ä½œç¢ºèª
    - è² è·ãƒ†ã‚¹ãƒˆã¨æœ€é©åŒ–

  âš ï¸ æ³¨æ„äº‹é …

  - ã‚³ã‚¹ãƒˆç®¡ç†: ä¸¦åˆ—åŒ–ã§APIå‘¼ã³å‡ºã—é »åº¦ãŒä¸ŠãŒã‚‹ãŸã‚ã€ã‚³ã‚¹ãƒˆç›£è¦–å¿…é ˆ
  - ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: çµæœã®é †åºä¿è¨¼ãŒå¿…è¦ãªå ´åˆã¯è¿½åŠ å®Ÿè£…è¦
  - ãƒ¡ãƒ¢ãƒªç®¡ç†: å¤§é‡ã‚¿ã‚¹ã‚¯æ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«æ³¨æ„
  - ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³: å‡¦ç†ä¸­ã®ã‚¿ã‚¹ã‚¯ã®é©åˆ‡ãªçµ‚äº†å‡¦ç†

  ã“ã®ææ¡ˆã«ã‚ˆã‚Šã€90åˆ†ä»¥ä¸Šã‹ã‹ã£ã¦ã„ãŸå‡¦ç†ã‚’15-20åˆ†ç¨‹åº¦ã«çŸ­ç¸®ã§ãã‚‹ã¨æœŸå¾…ã•ã‚Œã¾ã™ã€‚

> 1. ç’°å¢ƒæº–å‚™
    - Celery, Redis ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    - celery_config.py ä½œæˆ

ã‚’è¡¨ç¤ºã›ã‚ˆã€‚

âº 1. ç’°å¢ƒæº–å‚™ - Celery/Redis ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š

  ğŸ“¦ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

  # Celeryã¨é–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
  pip install celery[redis]==5.3.4
  pip install redis==5.0.1
  pip install flower==2.0.1  # ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç”¨
  pip install celery-progress==0.3  # é€²æ—è¡¨ç¤ºç”¨

  # æ—¢å­˜ã®requirements.txtã«è¿½åŠ 
  echo "celery[redis]==5.3.4" >> requirements.txt
  echo "redis==5.0.1" >> requirements.txt
  echo "flower==2.0.1" >> requirements.txt
  echo "celery-progress==0.3" >> requirements.txt

  ğŸ³ Redis ã‚µãƒ¼ãƒãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

  Docker Composeãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°

  # docker-compose/docker-compose.yml ã«è¿½åŠ 
  version: '3.8'

  services:
    qdrant:
      image: qdrant/qdrant
      ports:
        - "6333:6333"
      volumes:
        - qdrant_data:/qdrant/storage

    redis:
      image: redis:7-alpine
      ports:
        - "6379:6379"
      command: redis-server --appendonly yes
      volumes:
        - redis_data:/data
      healthcheck:
        test: ["CMD", "redis-cli", "ping"]
        interval: 5s
        timeout: 3s
        retries: 5

  volumes:
    qdrant_data:
    redis_data:

  Redisèµ·å‹•

  # Docker Composeã§èµ·å‹•
  docker-compose -f docker-compose/docker-compose.yml up -d redis

  # ã¾ãŸã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§Redisã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆMacï¼‰
  brew install redis
  brew services start redis

  # Ubuntu/Debian
  sudo apt-get update
  sudo apt-get install redis-server
  sudo systemctl start redis-server

  âš™ï¸ celery_config.py ã®ä½œæˆ

  # celery_config.py
  """
  Celeryè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
  Q/Aç”Ÿæˆã‚¿ã‚¹ã‚¯ã®ä¸¦åˆ—å‡¦ç†ç”¨è¨­å®š
  """

  import os
  from kombu import Exchange, Queue
  from celery import Celery
  from dotenv import load_dotenv

  # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
  load_dotenv()

  # Celeryã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
  app = Celery('qa_generation')

  # Redisè¨­å®š
  REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')

  # Celeryè¨­å®šã‚¯ãƒ©ã‚¹
  class CeleryConfig:
      # ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼è¨­å®šï¼ˆRedisï¼‰
      broker_url = REDIS_URL
      result_backend = REDIS_URL

      # ã‚¿ã‚¹ã‚¯è¨­å®š
      task_serializer = 'json'
      accept_content = ['json']
      result_serializer = 'json'
      timezone = 'Asia/Tokyo'
      enable_utc = True

      # ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®š
      worker_prefetch_multiplier = 1  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä¸€åº¦ã«å–å¾—ã™ã‚‹ã‚¿ã‚¹ã‚¯æ•°
      worker_max_tasks_per_child = 50  # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯¾ç­–
      worker_disable_rate_limits = False

      # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œè¨­å®š
      task_acks_late = True  # ã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã«ACK
      task_reject_on_worker_lost = True
      task_time_limit = 300  # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5åˆ†ï¼‰
      task_soft_time_limit = 270  # ã‚½ãƒ•ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ4.5åˆ†ï¼‰

      # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆOpenAI APIåˆ¶é™å¯¾å¿œï¼‰
      task_annotations = {
          'tasks.process_chunk_task': {
              'rate_limit': '50/m',  # åˆ†ã‚ãŸã‚Š50ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
          },
          'tasks.process_batch_task': {
              'rate_limit': '10/m',  # åˆ†ã‚ãŸã‚Š10ãƒãƒƒãƒ
          }
      }

      # ã‚­ãƒ¥ãƒ¼è¨­å®š
      task_routes = {
          'tasks.process_chunk_task': 'high_priority',
          'tasks.process_batch_task': 'normal_priority',
          'tasks.aggregate_results_task': 'low_priority',
      }

      # ã‚­ãƒ¥ãƒ¼å®šç¾©
      task_queues = (
          Queue('high_priority', Exchange('high_priority'), routing_key='high'),
          Queue('normal_priority', Exchange('normal_priority'), routing_key='normal'),
          Queue('low_priority', Exchange('low_priority'), routing_key='low'),
      )

      # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
      task_autoretry_for = (Exception,)
      task_retry_kwargs = {
          'max_retries': 3,
          'countdown': 60,  # 60ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤
          'retry_jitter': True,  # ã‚¸ãƒƒã‚¿ãƒ¼è¿½åŠ 
      }

      # çµæœã®æœ‰åŠ¹æœŸé™
      result_expires = 3600  # 1æ™‚é–“

      # Celery Beatè¨­å®šï¼ˆå®šæœŸã‚¿ã‚¹ã‚¯ç”¨ï¼‰
      beat_schedule = {
          'cleanup-old-results': {
              'task': 'tasks.cleanup_old_results',
              'schedule': 3600.0,  # 1æ™‚é–“ã”ã¨
          },
      }

  # è¨­å®šã‚’é©ç”¨
  app.config_from_object(CeleryConfig())

  # OpenAI APIè¨­å®š
  OPENAI_CONFIG = {
      'api_key': os.getenv('OPENAI_API_KEY'),
      'models': {
          'gpt-5-mini': {
              'rpm_limit': 3500,  # Requests Per Minute
              'tpm_limit': 200000,  # Tokens Per Minute
              'max_retries': 3,
              'retry_delay': 60
          },
          'gpt-4': {
              'rpm_limit': 500,
              'tpm_limit': 40000,
              'max_retries': 3,
              'retry_delay': 120
          }
      }
  }

  # ãƒ­ã‚°è¨­å®š
  LOGGING_CONFIG = {
      'version': 1,
      'disable_existing_loggers': False,
      'formatters': {
          'default': {
              'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
          },
      },
      'handlers': {
          'console': {
              'class': 'logging.StreamHandler',
              'formatter': 'default',
          },
          'file': {
              'class': 'logging.FileHandler',
              'filename': 'logs/celery_qa_generation.log',
              'formatter': 'default',
          },
      },
      'loggers': {
          'celery': {
              'handlers': ['console', 'file'],
              'level': 'INFO',
          },
          'tasks': {
              'handlers': ['console', 'file'],
              'level': 'DEBUG',
          },
      },
  }

  # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  __all__ = ['app', 'CeleryConfig', 'OPENAI_CONFIG', 'LOGGING_CONFIG']

  if __name__ == '__main__':
      # è¨­å®šç¢ºèªç”¨
      print("Celery Configuration:")
      print(f"Broker URL: {CeleryConfig.broker_url}")
      print(f"Result Backend: {CeleryConfig.result_backend}")
      print(f"Task Time Limit: {CeleryConfig.task_time_limit}s")
      print("\nOpenAI Configuration:")
      for model, config in OPENAI_CONFIG['models'].items():
          print(f"  {model}: RPM={config['rpm_limit']}, TPM={config['tpm_limit']}")

  ğŸ” ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆ.envï¼‰

  # .envãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
  REDIS_URL=redis://localhost:6379/0
  CELERY_BROKER_URL=redis://localhost:6379/0
  CELERY_RESULT_BACKEND=redis://localhost:6379/0

  # Flowerï¼ˆãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼‰è¨­å®š
  FLOWER_PORT=5555
  FLOWER_BASIC_AUTH=admin:password  # æœ¬ç•ªç’°å¢ƒã§ã¯å¼·åŠ›ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«å¤‰æ›´

  ğŸš€ Celeryãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

  # start_workers.sh
  #!/bin/bash

  # Celeryãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  echo "Starting Celery workers..."

  # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
  mkdir -p logs

  # é«˜å„ªå…ˆåº¦ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆ3ãƒ—ãƒ­ã‚»ã‚¹ï¼‰
  celery -A celery_config worker \
      --loglevel=info \
      --concurrency=3 \
      --hostname=worker_high@%h \
      --queues=high_priority \
      --logfile=logs/worker_high.log &

  # é€šå¸¸å„ªå…ˆåº¦ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆ2ãƒ—ãƒ­ã‚»ã‚¹ï¼‰
  celery -A celery_config worker \
      --loglevel=info \
      --concurrency=2 \
      --hostname=worker_normal@%h \
      --queues=normal_priority \
      --logfile=logs/worker_normal.log &

  # ä½å„ªå…ˆåº¦ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆ1ãƒ—ãƒ­ã‚»ã‚¹ï¼‰
  celery -A celery_config worker \
      --loglevel=info \
      --concurrency=1 \
      --hostname=worker_low@%h \
      --queues=low_priority \
      --logfile=logs/worker_low.log &

  # Flowerï¼ˆãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼‰èµ·å‹•
  celery -A celery_config flower \
      --port=${FLOWER_PORT:-5555} \
      --basic_auth=${FLOWER_BASIC_AUTH:-admin:password} &

  echo "Celery workers started!"
  echo "Monitor at: http://localhost:5555"

  ğŸ“Š å‹•ä½œç¢ºèª

  # Redisæ¥ç¶šç¢ºèª
  redis-cli ping
  # æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›: PONG

  # Celeryãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
  chmod +x start_workers.sh
  ./start_workers.sh

  # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
  celery -A celery_config status

  # Flowerã§ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
  # ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5555 ã‚’é–‹ã

  ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

  # RedisãŒèµ·å‹•ã—ãªã„å ´åˆ
  sudo systemctl status redis-server
  sudo journalctl -u redis-server -n 50

  # Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒæ¥ç¶šã§ããªã„å ´åˆ
  celery -A celery_config inspect ping

  # ãƒ­ã‚°ç¢ºèª
  tail -f logs/worker_*.log

  # ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
  ps aux | grep celery

