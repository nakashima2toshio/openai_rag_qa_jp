# python a42_qdrant_registration.py --recreate --include-answer

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
a42_qdrant_registration.py â€” 3ã¤ã®ç•°ãªã‚‹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¸ã®åˆ†é›¢ç™»éŒ²ç‰ˆ
--------------------------------------------------------------------------------
cc_newsãƒ‰ãƒ¡ã‚¤ãƒ³ã®Q&Aãƒ‡ãƒ¼ã‚¿ã‚’ã€ç”Ÿæˆæ–¹æ³•ã”ã¨ã«åˆ¥ã€…ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²ã—ã¾ã™ã€‚

ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆã€‘
- qa_cc_news_a02_llm    : a02_qa_pairs_cc_news.csv (LLMç”Ÿæˆæ–¹å¼)
- qa_cc_news_a03_rule   : a03_qa_pairs_cc_news.csv (ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆæ–¹å¼)
- qa_cc_news_a10_hybrid : a10_qa_pairs_cc_news.csv (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”Ÿæˆæ–¹å¼)

ã€ä¸»ãªå¤‰æ›´ç‚¹ï¼ˆa30ã¨ã®é•ã„ï¼‰ã€‘
- å˜ä¸€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ â†’ 3ã¤ã®ç‹¬ç«‹ã—ãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
- å„CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå°‚ç”¨ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒã¤
- domainã¨generation_methodãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰

ä½¿ã„æ–¹ï¼š
  # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆa20_output_qa_csv.pyã‚’å®Ÿè¡Œï¼‰
  python a20_output_qa_csv.py

  # 2. Qdrantã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
  export OPENAI_API_KEY=sk-...
  docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

  # 3. 3ã¤ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²
  python a42_qdrant_registration.py --recreate --include-answer

  # 4. ç‰¹å®šã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ç™»éŒ²
  python a42_qdrant_registration.py --collection qa_cc_news_a02_llm --recreate

  # 5. æ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆç‰¹å®šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
  python a42_qdrant_registration.py --search "æ°—å€™å¤‰å‹•" --collection qa_cc_news_a02_llm

ä¸»è¦å¼•æ•°ï¼š
  --recreate          : ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤â†’æ–°è¦ä½œæˆ
  --collection        : ç‰¹å®šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿å‡¦ç†ï¼ˆæŒ‡å®šãªã—ã§å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
  --qdrant-url        : æ—¢å®šã¯ http://localhost:6333
  --batch-size        : Embeddings/Upsert ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆæ—¢å®š 32ï¼‰
  --limit             : ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ä¸Šé™ï¼ˆé–‹ç™ºç”¨ã€0=ç„¡åˆ¶é™ï¼‰
  --include-answer    : åŸ‹ã‚è¾¼ã¿å…¥åŠ›ã« answer ã‚‚çµåˆï¼ˆquestion + "\\n" + answerï¼‰
  --search            : ã‚¯ã‚¨ãƒªæŒ‡å®šã§æ¤œç´¢ã®ã¿å®Ÿè¡Œ
  --topk              : ä¸Šä½ä»¶æ•°ï¼ˆæ—¢å®š5ï¼‰
"""
import argparse
import os
import json
import glob
from datetime import datetime, timezone
from typing import Dict, Iterable, List, Tuple, Optional, Any
from pathlib import Path

import pandas as pd

try:
    import yaml  # PyYAML
except Exception:
    yaml = None

try:
    import helper_api as hapi
except Exception:
    hapi = None

try:
    import helper_rag as hrag
except Exception:
    hrag = None

from qdrant_client import QdrantClient
from qdrant_client.http import models
from openai import OpenAI

# ------------------ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š ------------------
DEFAULTS = {
    "rag": {
        "include_answer_in_embedding": False,
    },
    "embeddings": {
        "primary": {"provider": "openai", "model": "text-embedding-3-small", "dims": 1536},
    },
    "qdrant": {"url": "http://localhost:6333"},
}

# ------------------ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®šç¾© ------------------
# CSVãƒ•ã‚¡ã‚¤ãƒ« â†’ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å â†’ ç”Ÿæˆæ–¹æ³•ã®ãƒãƒƒãƒ”ãƒ³ã‚°
COLLECTION_MAPPINGS = [
    {
        "csv_file": "qa_output/a02_qa_pairs_cc_news.csv",
        "collection": "qa_cc_news_a02_llm",
        "generation_method": "a02_make_qa",
        "domain": "cc_news",
        "description": "LLMç”Ÿæˆæ–¹å¼ï¼ˆa02_make_qa.pyï¼‰"
    },
    {
        "csv_file": "qa_output/a03_qa_pairs_cc_news.csv",
        "collection": "qa_cc_news_a03_rule",
        "generation_method": "a03_coverage",
        "domain": "cc_news",
        "description": "ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆæ–¹å¼ï¼ˆa03_rag_qa_coverage_improved.pyï¼‰"
    },
    {
        "csv_file": "qa_output/a10_qa_pairs_cc_news.csv",
        "collection": "qa_cc_news_a10_hybrid",
        "generation_method": "a10_hybrid",
        "domain": "cc_news",
        "description": "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”Ÿæˆæ–¹å¼ï¼ˆa10_qa_optimized_hybrid_batch.pyï¼‰"
    }
]


# ------------------ è¨­å®šãƒ­ãƒ¼ãƒ‰ ------------------
def load_config(path: str = "config.yml") -> Dict[str, Any]:
    cfg = {}
    if yaml and os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f) or {}
    # ãƒãƒ¼ã‚¸ï¼ˆæµ…ã„ãƒãƒ¼ã‚¸ã§ååˆ†ã€‚å¿…è¦ãªã‚‰æ·±ã„ãƒãƒ¼ã‚¸ã«å·®ã—æ›¿ãˆï¼‰
    def merge(dst, src):
        for k, v in src.items():
            if isinstance(v, dict) and isinstance(dst.get(k), dict):
                merge(dst[k], v)
            else:
                dst.setdefault(k, v)
    full = {}
    merge(full, DEFAULTS)
    merge(full, cfg)
    return full

# ------------------ å°é“å…· ------------------
def batched(seq: Iterable, size: int):
    buf = []
    for x in seq:
        buf.append(x)
        if len(buf) >= size:
            yield buf
            buf = []
    if buf:
        yield buf

# ------------------ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ------------------
def get_openai_client():
    if hapi and hasattr(hapi, "get_openai_client"):
        return hapi.get_openai_client()
    return OpenAI()

# ------------------ åŸ‹ã‚è¾¼ã¿å®Ÿè£…ï¼ˆhelperå„ªå…ˆï¼‰ ------------------
def embed_texts_openai(texts: List[str], model: str, client: Optional[OpenAI] = None) -> List[List[float]]:
    client = client or get_openai_client()
    resp = client.embeddings.create(model=model, input=texts)
    return [d.embedding for d in resp.data]

def embed_texts(texts: List[str], model: str, batch_size: int = 128) -> List[List[float]]:
    if hrag and hasattr(hrag, "embed_texts"):
        return hrag.embed_texts(texts, model=model, batch_size=batch_size)
    vecs: List[List[float]] = []
    client = get_openai_client()
    for chunk in batched(texts, batch_size):
        vecs.extend(embed_texts_openai(chunk, model=model, client=client))
    return vecs

# ------------------ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ ------------------
def build_inputs(df: pd.DataFrame, include_answer: bool) -> List[str]:
    if include_answer:
        return (df["question"].astype(str) + "\n" + df["answer"].astype(str)).tolist()
    return df["question"].astype(str).tolist()

# ------------------ CSVãƒ­ãƒ¼ãƒ‰ ------------------
def load_csv(path: str, required=("question", "answer"), limit: int = 0) -> pd.DataFrame:
    if not os.path.exists(path):
        raise FileNotFoundError(f"CSV not found: {path}")
    df = pd.read_csv(path)
    # åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¿…è¦ãªã‚‰ã“ã“ã§èª¿æ•´ï¼ˆä¾‹: 'Question'->'question'ï¼‰
    column_mappings = {
        'Question': 'question',
        'Response': 'answer',
        'Answer': 'answer',
        'correct_answer': 'answer'
    }
    df = df.rename(columns=column_mappings)
    for col in required:
        if col not in df.columns:
            raise ValueError(f"{path} ã«ã¯ '{col}' åˆ—ãŒå¿…è¦ã§ã™ï¼ˆåˆ—: {list(df.columns)}ï¼‰")
    df = df.fillna("").drop_duplicates(subset=list(required)).reset_index(drop=True)
    if limit and limit > 0:
        df = df.head(limit).copy()
    return df

# ------------------ Qdrant: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆNamed Vectorså¯¾å¿œï¼‰ ------------------
def create_or_recreate_collection(client: QdrantClient, name: str, recreate: bool,
                                  embeddings_cfg: Dict[str, Dict[str, Any]]):
    # embeddings_cfg: dict[name] = {"model": "...", "dims": int}
    # Named Vectorsï¼šè¤‡æ•°ã‚­ãƒ¼ãªã‚‰ dict ã‚’ã€å˜ä¸€ãªã‚‰ VectorParams ã‚’ä½¿ã†
    if len(embeddings_cfg) == 1:
        dims = list(embeddings_cfg.values())[0]["dims"]
        vectors_config = models.VectorParams(size=dims, distance=models.Distance.COSINE)
    else:
        # Named vectors
        vectors_config = {
            k: models.VectorParams(size=v["dims"], distance=models.Distance.COSINE)
            for k, v in embeddings_cfg.items()
        }
    if recreate:
        client.recreate_collection(collection_name=name, vectors_config=vectors_config)
    else:
        # ç„¡ã‘ã‚Œã°ä½œæˆ
        try:
            client.get_collection(name)
        except Exception:
            client.create_collection(collection_name=name, vectors_config=vectors_config)
    # ã‚ˆãä½¿ã†payloadã®ç´¢å¼•ï¼ˆä»»æ„ï¼‰
    try:
        client.create_payload_index(name, field_name="domain", field_type="keyword")
    except Exception:
        pass
    try:
        client.create_payload_index(name, field_name="generation_method", field_type="keyword")
    except Exception:
        pass

# ------------------ ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ï¼ˆNamed Vectorså¯¾å¿œï¼‰ ------------------
def build_points(df: pd.DataFrame, vectors_by_name: Dict[str, List[List[float]]], domain: str, source_file: str,
                 generation_method: str = None) -> List[models.PointStruct]:
    # vectors_by_name: name -> list[vec]
    n = len(df)
    for name, vecs in vectors_by_name.items():
        if len(vecs) != n:
            raise ValueError(f"vectors length mismatch for '{name}': df={n}, vecs={len(vecs)}")
    now_iso = datetime.now(timezone.utc).isoformat()
    points: List[models.PointStruct] = []
    for i, row in enumerate(df.itertuples(index=False)):
        payload = {
            "domain": domain,
            "generation_method": generation_method or "unknown",
            "question": getattr(row, "question"),
            "answer": getattr(row, "answer"),
            "source": os.path.basename(source_file),
            "created_at": now_iso,
            "schema": "qa:v1",
        }
        # Qdrant requires point IDs to be UUID or unsigned integer
        pid = hash(f"{domain}-{generation_method}-{i}") & 0x7FFFFFFF  # Convert to positive 32-bit integer
        if len(vectors_by_name) == 1:
            # å˜ä¸€ãƒ™ã‚¯ãƒˆãƒ«
            vec = list(vectors_by_name.values())[0][i]
            points.append(models.PointStruct(id=pid, vector=vec, payload=payload))
        else:
            # Named Vectorsï¼ˆdictæ¸¡ã—ï¼‰
            vecs_dict = {name: vecs[i] for name, vecs in vectors_by_name.items()}
            points.append(models.PointStruct(id=pid, vector=vecs_dict, payload=payload))
    return points

def upsert_points(client: QdrantClient, collection: str, points: List[models.PointStruct], batch_size: int = 128) -> int:
    count = 0
    for chunk in batched(points, batch_size):
        client.upsert(collection_name=collection, points=chunk)
        count += len(chunk)
    return count

# ------------------ æ¤œç´¢ï¼ˆNamed Vectorså¯¾å¿œï¼‰ ------------------
def embed_one(text: str, model: str) -> List[float]:
    return embed_texts([text], model=model, batch_size=1)[0]

def search(client: QdrantClient, collection: str, query: str, using_vec: str, model_for_using: str,
           topk: int = 5, domain: Optional[str] = None, generation_method: Optional[str] = None):
    qvec = embed_one(query, model=model_for_using)
    qfilter = None
    filter_conditions = []
    if domain:
        filter_conditions.append(models.FieldCondition(key="domain", match=models.MatchValue(value=domain)))
    if generation_method:
        filter_conditions.append(models.FieldCondition(key="generation_method", match=models.MatchValue(value=generation_method)))
    if filter_conditions:
        qfilter = models.Filter(must=filter_conditions)
    
    # ãƒ™ã‚¯ãƒˆãƒ«è¨­å®šã‚’ç¢ºèªã—ã¦é©åˆ‡ãªæ¤œç´¢æ–¹æ³•ã‚’é¸æŠ
    try:
        collection_info = client.get_collection(collection)
        # Named Vectorsã‹ã©ã†ã‹ç¢ºèª
        has_named_vectors = hasattr(collection_info.config.params.vectors, '__iter__') and not isinstance(
            collection_info.config.params.vectors, (str, models.VectorParams))
        
        if has_named_vectors and using_vec:
            # Named Vectorsã®å ´åˆã€usingå¼•æ•°ã‚’è©¦ã™
            try:
                hits = client.search(collection_name=collection, query_vector=qvec, limit=topk,
                                   query_filter=qfilter, using=using_vec)
            except (TypeError, Exception):
                # usingå¼•æ•°ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯ä»–ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                hits = client.search(collection_name=collection, query_vector=qvec, limit=topk,
                                   query_filter=qfilter)
        else:
            # å˜ä¸€ãƒ™ã‚¯ãƒˆãƒ«ã®å ´åˆã€usingå¼•æ•°ãªã—ã§æ¤œç´¢
            hits = client.search(collection_name=collection, query_vector=qvec, limit=topk,
                               query_filter=qfilter)
    except Exception:
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ãŒå–å¾—ã§ããªã„å ´åˆã€usingå¼•æ•°ãªã—ã§æ¤œç´¢
        hits = client.search(collection_name=collection, query_vector=qvec, limit=topk,
                           query_filter=qfilter)
    
    return hits

# ------------------ ãƒ¡ã‚¤ãƒ³ ------------------
def main():
    cfg = load_config("config.yml")
    rag_cfg = cfg.get("rag", {})
    embeddings_cfg: Dict[str, Dict[str, Any]] = cfg.get("embeddings", {})
    qdrant_url = (cfg.get("qdrant", {}) or {}).get("url", "http://localhost:6333")

    ap = argparse.ArgumentParser(
        description="3ã¤ã®Q&Aãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãã‚Œãã‚Œç‹¬ç«‹ã—ãŸQdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²"
    )
    ap.add_argument("--recreate", action="store_true",
                    help="Drop & create collection before upsert.")
    ap.add_argument("--collection", default=None,
                    help="ç‰¹å®šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿å‡¦ç†ï¼ˆæŒ‡å®šãªã—ã§å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰")
    ap.add_argument("--qdrant-url", default=qdrant_url)
    ap.add_argument("--batch-size", type=int, default=32)
    ap.add_argument("--limit", type=int, default=0,
                    help="Row limit per CSV for development (0=all)")
    ap.add_argument("--include-answer", action="store_true",
                    default=rag_cfg.get("include_answer_in_embedding", False),
                    help="Use 'question\\nanswer' as embedding input.")
    ap.add_argument("--search", default=None, help="Run search only.")
    ap.add_argument("--topk", type=int, default=5)
    args = ap.parse_args()

    if not embeddings_cfg:
        embeddings_cfg = DEFAULTS["embeddings"]

    # Qdrant client
    client = QdrantClient(url=args.qdrant_url, timeout=300)

    # æ¤œç´¢ã®ã¿
    if args.search:
        if not args.collection:
            print("[ERROR] æ¤œç´¢ã«ã¯ --collection ã®æŒ‡å®šãŒå¿…è¦ã§ã™")
            return

        model = embeddings_cfg["primary"]["model"]
        hits = search(client, args.collection, args.search, "primary", model, topk=args.topk)

        print(f"\n[Search] collection={args.collection} query={args.search!r}")
        for h in hits:
            method = h.payload.get('generation_method', 'unknown')
            question = h.payload.get('question', '')[:80]
            answer = h.payload.get('answer', '')[:80]
            print(f"score={h.score:.4f}  method={method}  Q: {question}  A: {answer}...")
        return

    # å‡¦ç†å¯¾è±¡ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
    if args.collection:
        # ç‰¹å®šã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿
        target_mappings = [m for m in COLLECTION_MAPPINGS if m["collection"] == args.collection]
        if not target_mappings:
            print(f"[ERROR] ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{args.collection}' ã¯å®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print(f"åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {[m['collection'] for m in COLLECTION_MAPPINGS]}")
            return
    else:
        # å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        target_mappings = COLLECTION_MAPPINGS

    # ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆå‡¦ç†
    print(f"\n[INFO] å‡¦ç†å¯¾è±¡: {len(target_mappings)} ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
    print("=" * 80)

    total = 0
    for mapping in target_mappings:
        csv_file = mapping["csv_file"]
        collection_name = mapping["collection"]
        generation_method = mapping["generation_method"]
        domain = mapping["domain"]
        description = mapping["description"]

        print(f"\nğŸ“¦ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection_name}")
        print(f"   èª¬æ˜: {description}")
        print(f"   ã‚½ãƒ¼ã‚¹: {csv_file}")
        print("-" * 80)

        if not os.path.exists(csv_file):
            print(f"[WARN] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file} (ã‚¹ã‚­ãƒƒãƒ—)")
            continue

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
        create_or_recreate_collection(client, collection_name, args.recreate, embeddings_cfg)

        # CSVãƒ­ãƒ¼ãƒ‰
        df = load_csv(csv_file, limit=args.limit)
        print(f"   ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df):,}ä»¶")

        texts = build_inputs(df, include_answer=args.include_answer)

        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        vectors_by_name: Dict[str, List[List[float]]] = {}
        for name, vcfg in embeddings_cfg.items():
            print(f"   åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­: {name} (model={vcfg['model']})... ", end="", flush=True)
            vectors_by_name[name] = embed_texts(texts, model=vcfg["model"], batch_size=args.batch_size)
            print("âœ“")

        # ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ã¨ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
        points = build_points(df, vectors_by_name, domain, csv_file, generation_method)
        print(f"   ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­... ", end="", flush=True)
        n = upsert_points(client, collection_name, points, batch_size=args.batch_size)
        print(f"âœ“ {n:,}ä»¶")

        total += n

    print("\n" + "=" * 80)
    print(f"âœ… å®Œäº†: ç·ç™»éŒ²ä»¶æ•° {total:,}ä»¶")

    # æ¤œè¨¼æ¤œç´¢
    print(f"\n[INFO] æ¤œè¨¼æ¤œç´¢ã‚’å®Ÿè¡Œä¸­...")
    model = embeddings_cfg["primary"]["model"]

    for mapping in target_mappings:
        collection_name = mapping["collection"]
        try:
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
            info = client.get_collection(collection_name)
            print(f"\n  {collection_name}: {info.points_count:,}ä»¶ç™»éŒ²æ¸ˆã¿")

            # ã‚µãƒ³ãƒ—ãƒ«æ¤œç´¢
            hits = search(client, collection_name, "æ°—å€™å¤‰å‹•", "primary", model, topk=2)
            if hits:
                for h in hits[:1]:
                    q = h.payload.get('question', '')[:50]
                    print(f"    ã‚µãƒ³ãƒ—ãƒ«æ¤œç´¢çµæœ: score={h.score:.4f}  Q: {q}...")
        except Exception as e:
            print(f"    æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()
