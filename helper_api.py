# helper_api.py
# OpenAI APIé–¢é€£ã¨ã‚³ã‚¢æ©Ÿèƒ½
# -----------------------------------------
import re
import time
import json
import logging
import logging.handlers
from logging import Logger

import yaml
import os
from typing import List, Dict, Any, Optional, Union, Tuple, Literal, Callable
from pathlib import Path
from dataclasses import dataclass
from functools import wraps
from datetime import datetime
from abc import ABC, abstractmethod
import hashlib

import tiktoken
from openai import OpenAI

# -----------------------------------------------------
# OpenAI APIå‹å®šç¾©
# -----------------------------------------------------
from openai.types.responses import (
    EasyInputMessageParam,
    ResponseInputTextParam,
    ResponseInputImageParam,
    Response
)
from openai.types.chat import (
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
)

# Roleå‹ã®å®šç¾©
RoleType = Literal["user", "assistant", "system", "developer"]


# ==================================================
# è¨­å®šç®¡ç†
# ==================================================
class ConfigManager:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†"""

    _instance = None

    def __new__(cls, config_path: str = "config.yml"):
        """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¨­å®šã‚’ç®¡ç†"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, config_path: str = "config.yml"):
        if hasattr(self, '_initialized'):
            return
        self._initialized = True
        self.config_path = Path(config_path)
        self._config = self._load_config()
        self._cache = {}
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
        logger = logging.getLogger('openai_helper')

        # æ—¢ã«è¨­å®šæ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if logger.handlers:
            return logger

        log_config = self.get("logging", {})
        level = getattr(logging, log_config.get("level", "INFO"))
        logger.setLevel(level)

        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®è¨­å®š
        formatter = logging.Formatter(
            log_config.get("format", "%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        )

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        log_file = log_config.get("file")
        if log_file:
            file_handler = logging.handlers.RotatingFileHandler(
                log_file,
                maxBytes=log_config.get("max_bytes", 10485760),
                backupCount=log_config.get("backup_count", 5)
            )
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)

        return logger


    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    # ç’°å¢ƒå¤‰æ•°ã§ã®è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
                    self._apply_env_overrides(config)
                    return config
            except Exception as e:
                print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                return self._get_default_config()
        else:
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
            return self._get_default_config()


    def _apply_env_overrides(self, config: Dict[str, Any]) -> None:
        """ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰"""
        # OpenAI API Key
        if os.getenv("OPENAI_API_KEY"):
            config.setdefault("api", {})["openai_api_key"] = os.getenv("OPENAI_API_KEY")

        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
        if os.getenv("LOG_LEVEL"):
            config.setdefault("logging", {})["level"] = os.getenv("LOG_LEVEL")

        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        if os.getenv("DEBUG_MODE"):
            config.setdefault("experimental", {})["debug_mode"] = os.getenv("DEBUG_MODE").lower() == "true"


    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            "models"        : {
                "default"  : "gpt-5-mini",
                "available": ["gpt-4o-mini", "gpt-4o", "gpt-4.1", "gpt-4.1-mini"]
            },
            "api"           : {
                "timeout"       : 30,
                "max_retries"   : 3,
                "openai_api_key": None
            },
            "ui"            : {
                "page_title": "OpenAI API Demo",
                "page_icon" : "ğŸ¤–",
                "layout"    : "wide"
            },
            "cache"         : {
                "enabled" : True,
                "ttl"     : 3600,
                "max_size": 100
            },
            "logging"       : {
                "level"       : "INFO",
                "format"      : "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                "file"        : None,
                "max_bytes"   : 10485760,
                "backup_count": 5
            },
            "error_messages": {
                "general_error"  : "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "api_key_missing": "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "network_error"  : "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
            },
            "experimental"  : {
                "debug_mode"            : False,
                "performance_monitoring": True
            }
        }

    def get(self, key: str, default: Any = None) -> Any:
        """è¨­å®šå€¤ã®å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        if key in self._cache:
            return self._cache[key]

        keys = key.split('.')
        value = self._config
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                value = default
                break

        result = value if value is not None else default
        self._cache[key] = result
        return result

    def set(self, key: str, value: Any) -> None:
        """è¨­å®šå€¤ã®æ›´æ–°"""
        keys = key.split('.')
        config = self._config
        for k in keys[:-1]:
            config = config.setdefault(k, {})
        config[keys[-1]] = value

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        self._cache.pop(key, None)

    def reload(self):
        """è¨­å®šã®å†èª­ã¿è¾¼ã¿"""
        self._config = self._load_config()
        self._cache.clear()

    def save(self, filepath: str = None) -> bool:
        """è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            save_path = Path(filepath) if filepath else self.config_path
            with open(save_path, 'w', encoding='utf-8') as f:
                yaml.safe_dump(self._config, f, default_flow_style=False, allow_unicode=True)
            return True
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False


# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
config = ConfigManager("config.yml")
logger = config.logger


# ==================================================
# ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
# ==================================================
class MemoryCache:
    """ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""

    def __init__(self):
        self._storage = {}
        self._enabled = config.get("cache.enabled", True)
        self._ttl = config.get("cache.ttl", 3600)
        self._max_size = config.get("cache.max_size", 100)

    def get(self, key: str) -> Any:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å€¤ã‚’å–å¾—"""
        if not self._enabled or key not in self._storage:
            return None

        cached_data = self._storage[key]
        if time.time() - cached_data['timestamp'] > self._ttl:
            del self._storage[key]
            return None

        return cached_data['result']

    def set(self, key: str, value: Any) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å€¤ã‚’è¨­å®š"""
        if not self._enabled:
            return

        self._storage[key] = {
            'result'   : value,
            'timestamp': time.time()
        }

        # ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self._storage) > self._max_size:
            oldest_key = min(self._storage, key=lambda k: self._storage[k]['timestamp'])
            del self._storage[oldest_key]

    def clear(self) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self._storage.clear()

    def size(self) -> int:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º"""
        return len(self._storage)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
cache = MemoryCache()


# ==================================================
# å®‰å…¨ãªJSONå‡¦ç†é–¢æ•°
# ==================================================
def safe_json_serializer(obj: Any) -> Any:
    """
    ã‚«ã‚¹ã‚¿ãƒ JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼
    OpenAI APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã©ã€æ¨™æº–ã§ã¯å‡¦ç†ã§ããªã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¤‰æ›
    """
    # Pydantic ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
    if hasattr(obj, 'model_dump'):
        try:
            return obj.model_dump()
        except Exception:
            pass

    # dict() ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚‹å ´åˆ
    if hasattr(obj, 'dict'):
        try:
            return obj.dict()
        except Exception:
            pass

    # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
    if isinstance(obj, datetime):
        return obj.isoformat()

    # OpenAI ResponseUsage ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆï¼ˆæ‰‹å‹•å±æ€§æŠ½å‡ºï¼‰
    if hasattr(obj, 'prompt_tokens') and hasattr(obj, 'completion_tokens'):
        return {
            'prompt_tokens'    : getattr(obj, 'prompt_tokens', 0),
            'completion_tokens': getattr(obj, 'completion_tokens', 0),
            'total_tokens'     : getattr(obj, 'total_tokens', 0)
        }

    # ãã®ä»–ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯æ–‡å­—åˆ—åŒ–
    return str(obj)


def safe_json_dumps(data: Any, **kwargs) -> str:
    """å®‰å…¨ãªJSONæ–‡å­—åˆ—åŒ–"""
    default_kwargs = {
        'ensure_ascii': False,
        'indent'      : 2,
        'default'     : safe_json_serializer
    }
    default_kwargs.update(kwargs)

    try:
        return json.dumps(data, **default_kwargs)
    except Exception as e:
        logger.error(f"JSON serialization error: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ–‡å­—åˆ—åŒ–
        return json.dumps(str(data), **{k: v for k, v in default_kwargs.items() if k != 'default'})


# ==================================================
# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆAPIç”¨ï¼‰
# ==================================================
def error_handler(func):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆAPIç”¨ï¼‰"""

    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}")
            # APIç”¨ã§ã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿã•ã›ã‚‹
            raise

    return wrapper


def timer(func):
    """å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆAPIç”¨ï¼‰"""

    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        execution_time = end_time - start_time
        logger.info(f"{func.__name__} took {execution_time:.2f} seconds")
        return result

    return wrapper


def cache_result(ttl: int = None):
    """çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ï¼‰"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            if not config.get("cache.enabled", True):
                return func(*args, **kwargs)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ç”Ÿæˆ
            cache_key = f"{func.__name__}_{hashlib.md5(str(args).encode() + str(kwargs).encode()).hexdigest()}"

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return cached_result

            # é–¢æ•°å®Ÿè¡Œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            result = func(*args, **kwargs)
            cache.set(cache_key, result)
            return result

        return wrapper

    return decorator


# --------------------------------------------------
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€€responses-APIï¼ˆä¾‹ï¼‰ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºç”¨
# --------------------------------------------------
developer_text = (
    "You are a strong developer and good at teaching software developer professionals "
    "please provide an up-to-date, informed overview of the API by function, then show "
    "cookbook programs for each, and explain the API options."
    "ã‚ãªãŸã¯å¼·åŠ›ãªé–‹ç™ºè€…ã§ã‚ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºè€…ã®å°‚é–€å®¶ã«æ•™ãˆã‚‹ã®ãŒå¾—æ„ã§ã™ã€‚"
    "OpenAIã®APIã‚’æ©Ÿèƒ½åˆ¥ã«æœ€æ–°ã‹ã¤è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    "ãã‚Œãã‚Œã®APIã®ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¤ºã—APIã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
)
user_text = (
    "Organize and identify the problem and list the issues. "
    "Then, provide a solution procedure for the issues you have organized and identified, "
    "and solve the problems/issues according to the solution procedures."
    "ä¸å…·åˆã€å•é¡Œã‚’ç‰¹å®šã—ã€æ•´ç†ã—ã¦ç®‡æ¡æ›¸ãã§åˆ—æŒ™ãƒ»èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    "æ¬¡ã«ã€æ•´ç†ãƒ»ç‰¹å®šã—ãŸå•é¡Œç‚¹ã®è§£æ±ºæ‰‹é †ã‚’ç¤ºã—ãªã•ã„ã€‚"
    "æ¬¡ã«ã€è§£æ±ºæ‰‹é †ã«å¾“ã£ã¦å•é¡Œãƒ»èª²é¡Œã‚’è§£æ±ºã—ã¦ãã ã•ã„ã€‚"
)
assistant_text = "OpenAIã®APIã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€å…¬å¼openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¾¿åˆ©ã§ã™ã€‚å›ç­”ã¯æ—¥æœ¬èªã§"


def get_default_messages() -> list[EasyInputMessageParam]:

    return [
    EasyInputMessageParam(role="developer", content=developer_text),
    EasyInputMessageParam(role="user",      content=user_text),
    EasyInputMessageParam(role="assistant", content=assistant_text),
]

def append_user_message(append_text, image_url=None):
    return [
    EasyInputMessageParam(role="developer", content=developer_text),
    EasyInputMessageParam(role="user",      content=user_text),
    EasyInputMessageParam(role="assistant", content=assistant_text),
    EasyInputMessageParam(role="user", content=append_text),
]

def append_developer_message(append_text):
    return [
    EasyInputMessageParam(role="developer", content=developer_text),
    EasyInputMessageParam(role="user",      content=user_text),
    EasyInputMessageParam(role="assistant", content=assistant_text),
    EasyInputMessageParam(role="developer", content=append_text),
]

def append_assistant_message(append_text):
    return [
        EasyInputMessageParam(role="developer", content=developer_text),
        EasyInputMessageParam(role="user", content=user_text),
        EasyInputMessageParam(role="assistant", content=assistant_text),
        EasyInputMessageParam(role="assistant", content=append_text),
    ]

# ==================================================
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†
# ==================================================
class MessageManager:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ç®¡ç†ï¼ˆAPIç”¨ï¼‰"""

    def __init__(self, messages: List[EasyInputMessageParam] = None):
        self._messages = messages or self.get_default_messages()

    @staticmethod
    def get_default_messages() -> List[EasyInputMessageParam]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—"""
        default_messages = config.get("default_messages", {})

        developer_content = default_messages.get(
            "developer",
            "You are a helpful assistant specialized in software development."
        )
        user_content = default_messages.get(
            "user",
            "Please help me with my software development tasks."
        )
        assistant_content = default_messages.get(
            "assistant",
            "I'll help you with your software development needs. Please let me know what you'd like to work on."
        )

        return [
            EasyInputMessageParam(role="developer", content=developer_content),
            EasyInputMessageParam(role="user", content=user_content),
            EasyInputMessageParam(role="assistant", content=assistant_content),
        ]

    def add_message(self, role: RoleType, content: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ """
        valid_roles: List[RoleType] = ["user", "assistant", "system", "developer"]
        if role not in valid_roles:
            raise ValueError(f"Invalid role: {role}. Must be one of {valid_roles}")

        self._messages.append(EasyInputMessageParam(role=role, content=content))

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°åˆ¶é™
        limit = config.get("api.message_limit", 50)
        if len(self._messages) > limit:
            # æœ€åˆã®developerãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¿æŒ
            developer_msg = self._messages[0] if self._messages[0]['role'] == 'developer' else None
            self._messages = self._messages[-limit:]
            if developer_msg and self._messages[0]['role'] != 'developer':
                self._messages.insert(0, developer_msg)

    def get_messages(self) -> List[EasyInputMessageParam]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®å–å¾—"""
        return self._messages.copy()

    def clear_messages(self):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¯ãƒªã‚¢"""
        self._messages = self.get_default_messages()

    def export_messages(self) -> Dict[str, Any]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        return {
            'messages'   : self.get_messages(),
            'exported_at': datetime.now().isoformat()
        }

    def import_messages(self, data: Dict[str, Any]):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if 'messages' in data:
            self._messages = data['messages']


# ==================================================
# ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†
# ==================================================
class TokenManager:
    """ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ç®¡ç†ï¼ˆæ–°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰"""

    # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œè¡¨
    MODEL_ENCODINGS = {
        "gpt-4o"                   : "cl100k_base",
        "gpt-4o-mini"              : "cl100k_base",
        "gpt-4o-audio-preview"     : "cl100k_base",
        "gpt-4o-mini-audio-preview": "cl100k_base",
        "gpt-4.1"                  : "cl100k_base",
        "gpt-4.1-mini"             : "cl100k_base",
        "o1"                       : "cl100k_base",
        "o1-mini"                  : "cl100k_base",
        "o3"                       : "cl100k_base",
        "o3-mini"                  : "cl100k_base",
        "o4"                       : "cl100k_base",
        "o4-mini"                  : "cl100k_base",
    }

    @classmethod
    def count_tokens(cls, text: str, model: str = None) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        try:
            encoding_name = cls.MODEL_ENCODINGS.get(model, "cl100k_base")
            enc = tiktoken.get_encoding(encoding_name)
            return len(enc.encode(text))
        except Exception as e:
            logger.error(f"ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆ1æ–‡å­— = 0.5ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
            return len(text) // 2

    @classmethod
    def truncate_text(cls, text: str, max_tokens: int, model: str = None) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«åˆ‡ã‚Šè©°ã‚"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        try:
            encoding_name = cls.MODEL_ENCODINGS.get(model, "cl100k_base")
            enc = tiktoken.get_encoding(encoding_name)
            tokens = enc.encode(text)
            if len(tokens) <= max_tokens:
                return text
            return enc.decode(tokens[:max_tokens])
        except Exception as e:
            logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Šè©°ã‚ã‚¨ãƒ©ãƒ¼: {e}")
            estimated_chars = max_tokens * 2
            return text[:estimated_chars]

    @classmethod
    def estimate_cost(cls, input_tokens: int, output_tokens: int, model: str = None) -> float:
        """APIä½¿ç”¨ã‚³ã‚¹ãƒˆã®æ¨å®š"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        pricing = config.get("model_pricing", {})
        model_pricing = pricing.get(model, pricing.get("gpt-4o-mini"))

        if not model_pricing:
            model_pricing = {"input": 0.00015, "output": 0.0006}

        input_cost = (input_tokens / 1000) * model_pricing["input"]
        output_cost = (output_tokens / 1000) * model_pricing["output"]

        return input_cost + output_cost

    @classmethod
    def get_model_limits(cls, model: str) -> Dict[str, int]:
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å–å¾—"""
        limits = {
            "gpt-4o"      : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4o-mini" : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4.1"     : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4.1-mini": {"max_tokens": 128000, "max_output": 4096},
            "o1"          : {"max_tokens": 128000, "max_output": 32768},
            "o1-mini"     : {"max_tokens": 128000, "max_output": 65536},
            "o3"          : {"max_tokens": 200000, "max_output": 100000},
            "o3-mini"     : {"max_tokens": 200000, "max_output": 100000},
            "o4"          : {"max_tokens": 256000, "max_output": 128000},
            "o4-mini"     : {"max_tokens": 256000, "max_output": 128000},
        }
        return limits.get(model, {"max_tokens": 128000, "max_output": 4096})


# ==================================================
# ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
# ==================================================
class ResponseProcessor:
    """API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†"""

    @staticmethod
    def extract_text(response: Response) -> List[str]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        texts = []

        if hasattr(response, 'output'):
            for item in response.output:
                if hasattr(item, 'type') and item.type == "message":
                    if hasattr(item, 'content'):
                        for content in item.content:
                            if hasattr(content, 'type') and content.type == "output_text":
                                if hasattr(content, 'text'):
                                    texts.append(content.text)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: output_textå±æ€§
        if not texts and hasattr(response, 'output_text'):
            texts.append(response.output_text)

        return texts

    @staticmethod
    def _serialize_usage(usage_obj) -> Dict[str, Any]:
        """ResponseUsageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›"""
        if usage_obj is None:
            return {}

        # Pydantic ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
        if hasattr(usage_obj, 'model_dump'):
            try:
                return usage_obj.model_dump()
            except Exception:
                pass

        # dict() ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚‹å ´åˆ
        if hasattr(usage_obj, 'dict'):
            try:
                return usage_obj.dict()
            except Exception:
                pass

        # æ‰‹å‹•ã§å±æ€§ã‚’æŠ½å‡º
        usage_dict = {}
        for attr in ['prompt_tokens', 'completion_tokens', 'total_tokens']:
            if hasattr(usage_obj, attr):
                usage_dict[attr] = getattr(usage_obj, attr)

        return usage_dict

    @staticmethod
    def format_response(response: Response) -> Dict[str, Any]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ•´å½¢ï¼ˆJSON serializableï¼‰"""
        # usage ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å®‰å…¨ã«å¤‰æ›
        usage_obj = getattr(response, "usage", None)
        usage_dict = ResponseProcessor._serialize_usage(usage_obj)

        return {
            "id"        : getattr(response, "id", None),
            "model"     : getattr(response, "model", None),
            "created_at": getattr(response, "created_at", None),
            "text"      : ResponseProcessor.extract_text(response),
            "usage"     : usage_dict,
        }

    @staticmethod
    def save_response(response: Response, filename: str = None) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¿å­˜"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"response_{timestamp}.json"

        formatted = ResponseProcessor.format_response(response)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
        logs_dir = Path(config.get("paths.logs_dir", "logs"))
        logs_dir.mkdir(exist_ok=True)
        filepath = logs_dir / filename

        # ä¿å­˜
        save_json_file(formatted, str(filepath))

        return str(filepath)


# ==================================================
# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
# ==================================================
class OpenAIClient:
    """OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, api_key: str = None):
        if api_key is None:
            api_key = config.get("api.openai_api_key") or os.getenv("OPENAI_API_KEY")

        if not api_key:
            raise ValueError(config.get("error_messages.api_key_missing", "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"))

        self.client = OpenAI(api_key=api_key)

    @error_handler
    @timer
    def create_response(
        self,
        messages: List[EasyInputMessageParam] = None,
        *,
        input: List[EasyInputMessageParam] = None,
        model: str = None,
        **kwargs,
    ) -> Response:
        """Responses APIå‘¼ã³å‡ºã—

        `messages` å¼•æ•°ï¼ˆæ—§ä»•æ§˜ï¼‰ã¨ `input` å¼•æ•°ï¼ˆæ–°ä»•æ§˜ï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚
        ã„ãšã‚Œã‚‚æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã€‚
        """
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        # æ–°æ—§ä¸¡æ–¹ã®å¼•æ•°åã‚’ã‚µãƒãƒ¼ãƒˆ
        if input is None:
            input = messages
        if input is None:
            raise ValueError("messages or input must be provided")

        params = {
            "model": model,
            "input": input,
        }
        params.update(kwargs)

        return self.client.responses.create(**params)

    @error_handler
    @timer
    def create_chat_completion(self, messages: List[ChatCompletionMessageParam], model: str = None, **kwargs):
        """Chat Completions APIå‘¼ã³å‡ºã—"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        params = {
            "model"   : model,
            "messages": messages,
        }
        params.update(kwargs)

        return self.client.chat.completions.create(**params)


# ==================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==================================================
def sanitize_key(name: str) -> str:
    """ã‚­ãƒ¼ç”¨ã«å®‰å…¨ãªæ–‡å­—åˆ—ã¸å¤‰æ›"""
    return re.sub(r'[^0-9a-zA-Z_]', '_', name).lower()


def load_json_file(filepath: str) -> Optional[Dict[str, Any]]:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def save_json_file(data: Dict[str, Any], filepath: str) -> bool:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
    try:
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)

        # å®‰å…¨ãªJSONä¿å­˜ã‚’ä½¿ç”¨
        json_str = safe_json_dumps(data)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(json_str)
        return True
    except Exception as e:
        logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def format_timestamp(timestamp: Union[int, float, str] = None) -> str:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if timestamp is None:
        timestamp = time.time()

    if isinstance(timestamp, str):
        return timestamp

    return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")


def create_session_id() -> str:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆ"""
    return hashlib.md5(f"{time.time()}_{id(object())}".encode()).hexdigest()[:8]

# ==================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ==================================================
__all__ = [
    # å‹å®šç¾©
    'RoleType',

    # ã‚¯ãƒ©ã‚¹
    'ConfigManager',
    'MessageManager',
    'TokenManager',
    'ResponseProcessor',
    'OpenAIClient',
    'MemoryCache',

    # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    'error_handler',
    'timer',
    'cache_result',

    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    'sanitize_key',
    'load_json_file',
    'save_json_file',
    'format_timestamp',
    'create_session_id',
    'safe_json_serializer',
    'safe_json_dumps',

    # å®šæ•°
    'developer_text',
    'user_text',
    'assistant_text',

    # ã‚°ãƒ­ãƒ¼ãƒãƒ«
    'config',
    'logger',
    'cache',
]
