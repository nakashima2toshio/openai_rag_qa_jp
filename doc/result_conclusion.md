# カバレージ分析結果の総合比較レポート

## エグゼクティブサマリー

3つの異なる実装方式（a02, a03, a10）でQ&Aペア生成とカバレージ分析を実施。最高カバレージは **a03方式で92.8%** を達成。処理効率とカバレージのバランスでは **a10方式が最適** という結果となった。

---

## 1. 方式別比較表

### 1.1 実装アプローチの比較


| 項目                   | a02_make_qa.py                                                                                                                                    | a03_rag_qa_coverage_improved.py                                                                          | a10_qa_optimized_hybrid_batch.py                                                               |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **カバレージ計算方式** | 多段階カバレージ分析（3段階閾値）                                                                                                                 | 単一閾値（0.6）によるカバレージ分析                                                                      | 文書単位の平均カバレージ計算                                                                   |
| **チャンク処理方法**   | - チャンクマージ機能<br>- 動的Q&A数調整<br>- 位置バイアス補正                                                                                     | - セマンティックチャンキング<br>- 文境界保持<br>- 固定チャンクサイズ（200トークン）                      | - 文書単位バッチ処理<br>- ハイブリッド方式<br>- 10文書/バッチ                                  |
| **Q/A生成方法**        | - バッチ処理（5チャンク/バッチ）<br>- チャンク特性別Q&A数決定<br>- 質問タイプ指定                                                                 | - 多様な質問タイプ生成<br>- コンテキスト依存<br>- キーワードベース混合                                   | - 文書全体からの生成<br>- コンテキスト保持<br>- 効率重視                                       |
| **実行コマンド**       | `python a02_make_qa.py --dataset cc_news --batch-chunks 5 --merge-chunks --min-tokens 150 --max-tokens 400 --model gpt-5-mini --analyze-coverage` | `python a03_rag_qa_coverage_improved.py --dataset cc_news --model gpt-5-mini --output-dir qa_output/a03` | `python a10_qa_optimized_hybrid_batch.py --dataset cc_news --model gpt-5-mini --batch-size 10` |

---

## 2. 数値結果の比較

### 2.1 カバレージ率比較


| 方式    | Standard閾値(0.7) | 実測閾値 | カバー済みチャンク | 総チャンク数 | 達成率              |
| ------- | ----------------- | -------- | ------------------ | ------------ | ------------------- |
| **a02** | 70.6%             | 0.70     | 936                | 1,325        | ⭐⭐⭐              |
| **a03** | -                 | 0.60     | 1,567              | 1,689        | ⭐⭐⭐⭐⭐**92.8%** |
| **a10** | -                 | -        | -                  | 497文書      | ⭐⭐⭐⭐ 74.6%      |

### 2.2 Q&Aペア生成数比較


| 方式    | 生成Q&A数 | チャンク/文書数 | 平均Q&A/単位   | 生成効率               |
| ------- | --------- | --------------- | -------------- | ---------------------- |
| **a02** | 4,646     | 1,325チャンク   | 3.5個/チャンク | 中                     |
| **a03** | 4,478     | 1,689チャンク   | 2.7個/チャンク | 中                     |
| **a10** | 2,075     | 497文書         | 4.2個/文書     | **高（API削減95.4%）** |

### 2.3 詳細カバレージ分析（a02のみ）

#### 多段階カバレージ

- **Strict (0.80)**: 24.5%
- **Standard (0.70)**: 70.6%
- **Lenient (0.60)**: 94.0%

#### チャンク長別カバレージ

- **Short (<100 tokens)**: 68.0%
- **Medium (100-200 tokens)**: 81.4%
- **Long (>200 tokens)**: 68.7%

#### 位置別カバレージ

- **Beginning**: 73.5%
- **Middle**: 69.8%
- **End**: 68.6%

---

## 3. 質問タイプ別分布

### 3.1 a02方式の質問タイプ

```
- fact: 3,157件 (68.0%)          # 事実確認型（〜は何ですか？）
- reason: 804件 (17.3%)           # 理由説明型（なぜ〜ですか？）
- application: 410件 (8.8%)       # 応用型（〜はどのように活用されますか？）
- comparison: 274件 (5.9%)        # 比較型（〜と〜の違いは？）
- explanation: 1件 (0.02%)        # 説明型（生成エラーの可能性）
```

**各質問タイプの特徴:**
- **fact**: 「〜は何ですか？」「〜とは何を指しますか？」など、テキストから直接抽出可能な事実を問う
- **reason**: 「なぜ〜ですか？」「〜の理由は何ですか？」など、因果関係や背景を問う
- **application**: 「〜はどのように活用されますか？」「〜の使い方は？」など、実用面を問う
- **comparison**: 「〜と〜の違いは何ですか？」「〜は〜とどう異なりますか？」など、比較を求める

### 3.2 a03方式の質問タイプ

```
- contextual: 2,431件 (54.3%)     # 文脈依存型（前後関係を含む質問）
- keyword_based: 1,711件 (38.2%)  # キーワード抽出型（重要語句に関する質問）
- factual_detailed: 229件 (5.1%)  # 詳細事実型（特定情報の詳細説明）
- thematic: 105件 (2.3%)          # テーマ型（主要テーマに関する質問）
- comprehensive: 2件 (0.04%)      # 包括型（チャンク全体の要約質問）
```

**各質問タイプの特徴:**
- **contextual**: 「〜は〜とどのように関連しますか？」など、文章の前後関係を考慮した質問
- **keyword_based**: 「『キーワード』について何が述べられていますか？」など、抽出した重要語句に関する質問
- **factual_detailed**: 「〜について詳しく説明してください」など、特定情報の詳細な説明を求める質問
- **thematic**: 「主要テーマは何ですか？」「『トピック』に関する主要テーマは？」など、内容の主題を問う
- **comprehensive**: 「このセクションにはどのような情報が含まれていますか？」など、チャンク全体を包括する質問

### 3.3 a10方式の質問タイプ

#### 通常モード（効率重視）
```
※ 質問タイプの明示的な分類は実装されていない
- 文書単位で包括的にQ&Aを生成（タイプ分類なし）
- 平均4.2個/文書のQ&Aペアを生成
- 総数: 2,075件
```

#### 品質重視モード（2024年11月追加）
```
階層的Q&A生成による暗黙的分類:
- comprehensive（包括型）: 1-2件/文書    # 文書全体の要約
- paragraph_detail（詳細型）: 3-4件/文書  # 段落レベルの詳細
- entity_specific（特化型）: 5-6件/文書   # キーワード特化
- targeted_coverage（補完型）: 2-3件/文書 # 未カバー領域補完
合計: 11-15件/文書（目標）
```

**a10方式の特徴:**
- **通常モード**: 効率重視、文書全体から自然にQ&Aを生成
- **品質モード**: カバレージ95%目標、階層的生成で網羅性向上
- バッチ処理によりAPI呼び出しを95.4%削減

### 3.4 質問タイプ分布の比較分析

**アプローチの違い:**
- **a02**: OpenAI標準の4分類（fact/reason/application/comparison）を使用、factが68%と圧倒的多数
- **a03**: 独自の5分類を採用、contextual（54.3%）とkeyword_based（38.2%）で92.5%を占める
- **a10**: 分類なしで効率的に生成、文書単位の処理により自然な質問を生成

**カバレージへの影響:**
- a02の高いfact比率（68%）は直接的な情報抽出に偏っており、カバレージ70.6%に留まる一因
- a03のcontextual重視（54.3%）により文脈を含む広範囲のカバー（92.8%）を達成
- a10は分類にこだわらず実用的なQ&Aを生成し、効率とカバレージのバランス（74.6%）を実現

---

## 4. 処理効率の詳細比較

### 4.1 API利用数の詳細


| 方式    | LLM API呼び出し | 埋め込みAPI呼び出し | 総API呼び出し数 | 従来比較  | API削減率     |
| ------- | --------------- | ------------------- | --------------- | --------- | ------------- |
| **a02** | 約265回※1      | 約1,971回※2        | **約2,236回**   | -         | ベースライン  |
| **a03** | 約338回※3      | 約2,167回※4        | **約2,505回**   | +12.0%    | -             |
| **a10** | 50回            | 18回                | **68回**        | 1,491回比 | **95.4%削減** |

※1: 1,325チャンク÷5バッチ = 265回（バッチ処理）
※2: 1,325チャンク + 4,646Q&A÷3 = 約1,971回（埋め込み生成）
※3: 1,689チャンク÷5 = 約338回（推定）
※4: 1,689チャンク + 4,478Q&A÷3 = 約2,167回（埋め込み生成）

### 4.2 実行時間の実測と予測


| 方式    | 実測時間 | 予測時間（500文書） | 処理速度         | 時間効率 |
| ------- | -------- | ------------------- | ---------------- | -------- |
| **a02** | 未記載   | **約120-150分**※5  | 0.05-0.07文書/秒 | 低       |
| **a03** | 未記載   | **約100-130分**※6  | 0.06-0.08文書/秒 | 中       |
| **a10** | 52.14分  | **52.14分**（実測） | 0.16文書/秒      | **高**   |

※5: チャンク処理+マージ+カバレージ分析を考慮した推定
※6: セマンティックチャンキング+多様な質問タイプ生成を考慮した推定

### 4.3 コスト比較


| 方式    | 推定コスト（500文書） | コスト内訳                        | コスト効率 |
| ------- | --------------------- | --------------------------------- | ---------- |
| **a02** | **約$3.50-4.50**      | LLM:$1.50<br>埋め込み: $2.00-3.00 | 低         |
| **a03** | **約$3.80-4.80**      | LLM:$1.70<br>埋め込み: $2.10-3.10 | 低         |
| **a10** | **$0.1581**（実測）   | LLM:$0.12<br>埋め込み: $0.04      | **最高**   |

---

## 5. 各方式の特徴と長所・短所

### a02_make_qa.py

**長所:**

- 多段階カバレージ分析により詳細な品質評価が可能
- チャンク特性（長さ・位置）別の詳細分析
- 動的Q&A数調整による効率的な生成

**短所:**

- Standard閾値でのカバレージが70.6%と最も低い
- チャンク処理が複雑で実装難易度が高い

**推奨用途:** 詳細なカバレージ分析が必要な場合

### a03_rag_qa_coverage_improved.py

**長所:**

- **最高カバレージ92.8%を達成**
- セマンティックチャンキングによる高品質な分割
- 多様な質問タイプの自動生成

**短所:**

- 閾値が0.6と緩めの設定
- API効率が不明

**推奨用途:** カバレージ最大化が最優先の場合

### a10_qa_optimized_hybrid_batch.py

**長所:**

- **API削減率95.4%で最高効率**
- 処理速度とコストの最適化
- 文書単位の処理で文脈保持

**短所:**

- カバレージ74.6%でa03より劣る
- Q&A総数が最も少ない（2,075件）

**推奨用途:** 大規模処理でコスト効率を重視する場合

---

## 6. 総合評価と推奨事項

### 最適な選択基準

1. **カバレージ重視** → **a03方式**（92.8%達成）
2. **コスト効率重視** → **a10方式**（API削減95.4%）
3. **分析詳細度重視** → **a02方式**（多段階分析）

### 改善提案

#### a02の改善方向

- qa_per_chunkを3→5に増加
- バッチサイズを5→3に削減
- 目標: カバレージ70.6%→90%

#### a03の改善方向

- 閾値を0.6→0.7に引き上げて品質向上
- API効率の測定と最適化

#### a10の改善方向

- **品質モード実装済み（2024年11月）**:
  - 階層的Q&A生成（包括・詳細・特化の3層）
  - 動的Q/A数調整（8-15個/文書）
  - カバレージフィードバックループ（目標95%）
  - バッチサイズ自動調整（品質モードで5に制限）
- **使用方法**: `--quality-mode --target-coverage 0.95`

---

## 7. 結論

**最も実用的な選択:**

- **開発・テスト環境**: a03方式（高カバレージ）
- **本番環境**: a10方式（高効率）
- **詳細分析**: a02方式（多段階評価）

**ハイブリッドアプローチの提案:**

1. a10方式で効率的に初期Q&A生成
2. a03方式で未カバー領域を補完
3. a02方式で最終品質評価

これにより、**効率性とカバレージの両立**が可能となる。

---

*作成日: 2025年11月6日*
