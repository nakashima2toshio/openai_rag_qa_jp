# a10_qa_optimized_hybrid_batch.py - è©³ç´°è¨­è¨ˆæ›¸

## æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
- **æœ€çµ‚æ›´æ–°**: 2025-10-23
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.1 (å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæœ€é©åŒ–ç‰ˆ)
- **ä¸»è¦æ©Ÿèƒ½**: ãƒãƒƒãƒå‡¦ç†ã€APIå‘¼ã³å‡ºã—æœ€é©åŒ–ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Q/Aç”Ÿæˆ

---

## æ¦‚è¦

`a10_qa_optimized_hybrid_batch.py`ã¯ã€**ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹APIå‘¼ã³å‡ºã—æœ€é©åŒ–**ã‚’å®Ÿç¾ã—ãŸé«˜åº¦ãªQ&Aãƒšã‚¢ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚`a10_qa_optimized_hybrid.py`ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ãƒ™ãƒ¼ã‚¹ã«ã€**è¤‡æ•°æ–‡æ›¸ã‚’ä¸€åº¦ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†**ã™ã‚‹ã“ã¨ã§ã€APIå‘¼ã³å‡ºã—æ•°ã‚’**æœ€å¤§92%å‰Šæ¸›**ã—ã€å‡¦ç†é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã™ã€‚

**v1.1ã®æ–°æ©Ÿèƒ½**:
- å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’`qa_output/a10/`ã«å¤‰æ›´ï¼ˆã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè‡ªå‹•ä½œæˆï¼‰
- ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã®æ”¹å–„

---

## ãƒãƒƒãƒå‡¦ç†ã®é©æ–°æ€§

### å¾“æ¥ç‰ˆã¨ã®æ±ºå®šçš„ãªé•ã„

```
å¾“æ¥ç‰ˆï¼ˆå€‹åˆ¥å‡¦ç†ï¼‰:
æ–‡æ›¸1 â†’ APIå‘¼å‡º1
æ–‡æ›¸2 â†’ APIå‘¼å‡º2
æ–‡æ›¸3 â†’ APIå‘¼å‡º3
...
æ–‡æ›¸497 â†’ APIå‘¼å‡º497

ãƒãƒƒãƒç‰ˆï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰:
æ–‡æ›¸1-10 â†’ APIå‘¼å‡º1
æ–‡æ›¸11-20 â†’ APIå‘¼å‡º2
æ–‡æ›¸21-30 â†’ APIå‘¼å‡º3
...
æ–‡æ›¸491-497 â†’ APIå‘¼å‡º50
```

| å‡¦ç†æ–¹å¼ | 497æ–‡æ›¸ã®APIå‘¼å‡ºæ•° | å‡¦ç†æ™‚é–“ | ã‚³ã‚¹ãƒˆå‰Šæ¸›ç‡ |
|---------|-------------------|---------|------------|
| **å¾“æ¥ç‰ˆï¼ˆå€‹åˆ¥å‡¦ç†ï¼‰** | 497å› | ç´„3åˆ† | - |
| **ãƒãƒƒãƒç‰ˆï¼ˆãƒãƒƒãƒ10ï¼‰** | 50å› | ç´„1åˆ† | **90%å‰Šæ¸›** |
| **ãƒãƒƒãƒç‰ˆï¼ˆãƒãƒƒãƒ20ï¼‰** | 25å› | ç´„45ç§’ | **95%å‰Šæ¸›** |

### ãƒãƒƒãƒå‡¦ç†ã®3æ®µéšæœ€é©åŒ–

```
Stage 1: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æŠ½å‡ºï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ï¼‰
    â†“
Stage 2: LLMãƒãƒƒãƒå‡¦ç†ï¼ˆ497æ–‡æ›¸ â†’ 50å›ã®APIå‘¼å‡ºï¼‰
    â†“
Stage 3: åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒå‡¦ç†ï¼ˆ100æ–‡æ›¸ãšã¤ â†’ 5å›ã®APIå‘¼å‡ºï¼‰
    â†“
åˆè¨ˆ: 55å›ã®APIå‘¼å‡ºï¼ˆå¾“æ¥ç‰ˆ1,491å›ã‹ã‚‰96.3%å‰Šæ¸›ï¼‰
```

---

## æ¨å¥¨å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

### 95%ã‚«ãƒãƒ¬ãƒ¼ã‚¸é”æˆç‰ˆï¼ˆæ¨å¥¨ï¼‰

```bash
python a10_qa_optimized_hybrid_batch.py \
    --dataset cc_news \
    --model gpt-5-mini \
    --batch-size 10 \
    --embedding-batch-size 150 \
    --qa-count 12 \
    --max-docs 150 \
    --output qa_output
```

**æœŸå¾…çµæœ:**
- å‡¦ç†æ–‡æ›¸: 150ä»¶
- ç”ŸæˆQ/A: 1,800å€‹
- ã‚«ãƒãƒ¬ãƒ¼ã‚¸: 95%+
- APIå‘¼å‡º: ç´„20å›
- å‡¦ç†æ™‚é–“: 2-3åˆ†
- ã‚³ã‚¹ãƒˆ: $0.01-0.02
- å‡ºåŠ›å…ˆ: `qa_output/a10/` â­

---

## ä¸»è¦æ©Ÿèƒ½

### 1. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒå‡¦ç†

```python
class BatchHybridQAGenerator(OptimizedHybridQAGenerator):
    def __init__(self,
                 model: str = "gpt-5-mini",
                 embedding_model: str = "text-embedding-3-small",
                 batch_size: int = 10,              # LLMãƒãƒƒãƒã‚µã‚¤ã‚º
                 embedding_batch_size: int = 100):  # åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚º
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `batch_size`: LLMå‡¦ç†ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ã€æ¨å¥¨: 10-20ï¼‰
- `embedding_batch_size`: åŸ‹ã‚è¾¼ã¿å‡¦ç†ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ã€æ¨å¥¨: 100-200ï¼‰

### 2. çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½

å‡¦ç†å®Œäº†æ™‚ã«è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã‚’è‡ªå‹•è¡¨ç¤ºï¼š

```
================================================================================
ğŸ“Š ãƒãƒƒãƒå‡¦ç†çµ±è¨ˆ
================================================================================
å‡¦ç†æ–‡æ›¸æ•°: 497

LLMå‡¦ç†:
  - ãƒãƒƒãƒæ•°: 50
  - APIå‘¼ã³å‡ºã—: 50å›
  - å‰Šæ¸›ç‡: 90.0%

åŸ‹ã‚è¾¼ã¿å‡¦ç†:
  - ãƒãƒƒãƒæ•°: 5
  - APIå‘¼ã³å‡ºã—: 5å›

ç·åˆ:
  - ç·APIå‘¼ã³å‡ºã—: 55å›
  - å¾“æ¥æ–¹å¼: 1491å›
  - å‰Šæ¸›ç‡: 96.3%
================================================================================
```

### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€è‡ªå‹•çš„ã«å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼š

```python
try:
    # ãƒãƒƒãƒå‡¦ç†
    response = self.client.chat.completions.create(**api_params)
    batch_results = self._parse_batch_response(response)
except Exception as e:
    logger.warning(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}. å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    for i in range(len(batch_texts)):
        qa_pairs = self._template_to_qa(batch_rules[i])
        enhanced_results.append({"qa_pairs": qa_pairs})
```

---

## ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒãƒƒãƒå‡¦ç†ãƒ•ãƒ­ãƒ¼

```
ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿè¡Œï¼ˆ497æ–‡æ›¸ï¼‰
         â†“
BatchHybridQAGenerator åˆæœŸåŒ–ï¼ˆbatch_size=10ï¼‰
         â†“
ãƒãƒƒãƒå‡¦ç†ãƒ«ãƒ¼ãƒ—ï¼ˆ50å›ï¼‰
  â”œâ”€ 10æ–‡æ›¸ã‚’ãƒãƒƒãƒåŒ–
  â”œâ”€ OpenAI APIå‘¼å‡ºï¼ˆ1å›ã§10æ–‡æ›¸åˆ†ï¼‰
  â”œâ”€ ãƒãƒƒãƒå¿œç­”å—ä¿¡
  â””â”€ ãƒ‘ãƒ¼ã‚¹ï¼†æ ¼ç´
         â†“
åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒå‡¦ç†ï¼ˆ5å›ï¼‰
  â”œâ”€ 100æ–‡æ›¸ãšã¤ãƒãƒƒãƒåŒ–
  â”œâ”€ OpenAI Embeddings APIå‘¼å‡º
  â””â”€ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
         â†“
çµæœçµ±åˆï¼ˆ497æ–‡æ›¸åˆ†ï¼‰
         â†“
çµ±è¨ˆè¡¨ç¤ºï¼†çµæœä¿å­˜ï¼ˆqa_output/a10/ï¼‰â­
  â”œâ”€ batch_summary_{dataset}_{model}_b{batch_size}_{timestamp}.json
  â””â”€ batch_qa_pairs_{dataset}_{model}_b{batch_size}_{timestamp}.csv
```

---

## ã‚¯ãƒ©ã‚¹æ§‹æˆ

### BatchHybridQAGenerator ã‚¯ãƒ©ã‚¹

`OptimizedHybridQAGenerator`ã‚’ç¶™æ‰¿ã—ã€ãƒãƒƒãƒå‡¦ç†æ©Ÿèƒ½ã‚’è¿½åŠ 

```python
class BatchHybridQAGenerator(OptimizedHybridQAGenerator):
    """
    ãƒãƒƒãƒå‡¦ç†ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Q/Aç”Ÿæˆã‚¯ãƒ©ã‚¹
    APIå‘¼ã³å‡ºã—ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã€å‡¦ç†ã‚’é«˜é€ŸåŒ–
    """
```

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

| ãƒ¡ã‚½ãƒƒãƒ‰ | èª¬æ˜ | æœ€é©åŒ–å†…å®¹ |
|---------|------|----------|
| `generate_batch_hybrid_qa()` | è¤‡æ•°æ–‡æ›¸ã®ãƒãƒƒãƒå‡¦ç† | ä¸€åº¦ã®APIå‘¼å‡ºã§10æ–‡æ›¸å‡¦ç† |
| `_batch_enhance_with_llm()` | LLMãƒãƒƒãƒå“è³ªå‘ä¸Š | 50å› â†’ 5å›ï¼ˆ90%å‰Šæ¸›ï¼‰ |
| `_create_batch_prompt()` | ãƒãƒƒãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ | JSONå½¢å¼ã§è¤‡æ•°æ–‡æ›¸ã‚’çµ±åˆ |
| `_parse_batch_response()` | ãƒãƒƒãƒå¿œç­”ãƒ‘ãƒ¼ã‚¹ | document_idåˆ¥ã«åˆ†é›¢ |
| `_batch_calculate_coverage()` | ãƒãƒƒãƒã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®— | åŸ‹ã‚è¾¼ã¿ã‚’ä¸€æ‹¬ç”Ÿæˆ |
| `_batch_get_embeddings()` | åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒå–å¾— | 100æ–‡æ›¸ãšã¤å‡¦ç† |
| `_print_batch_statistics()` | çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ› | å‰Šæ¸›ç‡ã‚’å¯è¦–åŒ– |

---

## ä½¿ç”¨æ–¹æ³•

### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

#### åŸºæœ¬ä½¿ç”¨ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º10ï¼‰
```bash
python a10_qa_optimized_hybrid_batch.py --dataset cc_news
```

#### ãƒãƒƒãƒã‚µã‚¤ã‚ºæŒ‡å®š
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚º20ã§é«˜é€ŸåŒ–
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --batch-size 20

# åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚‚èª¿æ•´
python a10_qa_optimized_hybrid_batch.py --dataset cc_news \
    --batch-size 20 \
    --embedding-batch-size 200
```

#### ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
```bash
# GPT-5-miniã§å‡¦ç†
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --model gpt-5-mini

# GPT-4oã§é«˜å“è³ªå‡¦ç†
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --model gpt-4o
```

#### å‡¦ç†æ–‡æ›¸æ•°åˆ¶é™ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
```bash
# 10æ–‡æ›¸ã®ã¿å‡¦ç†
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --max-docs 10
```

#### Q/Aæ•°æŒ‡å®š
```bash
# æ–‡æ›¸ã‚ãŸã‚Š12å€‹ã®Q/Aç”Ÿæˆ
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --qa-count 12
```

#### ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼ˆã‚³ã‚¹ãƒˆ$0ï¼‰
```bash
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --no-llm
```

#### ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®—ãªã—ï¼ˆé«˜é€ŸåŒ–ï¼‰
```bash
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --no-coverage
```

#### æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ï¼ˆé€šå¸¸ç‰ˆ vs ãƒãƒƒãƒç‰ˆï¼‰
```bash
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --compare --compare-size 10
```

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®ä½¿ç”¨

```python
from helper_rag_qa import BatchHybridQAGenerator

# åˆæœŸåŒ–ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºæŒ‡å®šï¼‰
generator = BatchHybridQAGenerator(
    model="gpt-5-mini",
    batch_size=10,              # LLMãƒãƒƒãƒã‚µã‚¤ã‚º
    embedding_batch_size=100    # åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚º
)

# ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
texts = ["æ–‡æ›¸1...", "æ–‡æ›¸2...", "æ–‡æ›¸3...", ...]

results = generator.generate_batch_hybrid_qa(
    texts=texts,
    qa_count=5,
    use_llm=True,
    calculate_coverage=True,
    document_type="auto",
    show_progress=True
)

# çµæœã®å–å¾—
for i, result in enumerate(results):
    qa_pairs = result["qa_pairs"]
    coverage = result["coverage"]["coverage_percentage"]
    cost = result["api_usage"]["cost"]

    print(f"æ–‡æ›¸{i+1}: {len(qa_pairs)}å€‹ã®Q/A, ã‚«ãƒãƒ¬ãƒ¼ã‚¸{coverage:.1f}%, ã‚³ã‚¹ãƒˆ${cost:.4f}")

# ãƒãƒƒãƒçµ±è¨ˆã®ç¢ºèª
print(f"LLMãƒãƒƒãƒæ•°: {generator.batch_stats['llm_batches']}")
print(f"ç·APIå‘¼å‡º: {generator.batch_stats['total_llm_calls']}")
```

---

## ãƒãƒƒãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä»•çµ„ã¿

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ 

```json
{
  "instruction": "Process these 10 documents and generate Q&A pairs for each.",
  "documents": [
    {
      "document_id": 0,
      "text": "ãƒ†ã‚­ã‚¹ãƒˆ1...",
      "keywords": [...]
    },
    {
      "document_id": 1,
      "text": "ãƒ†ã‚­ã‚¹ãƒˆ2...",
      "keywords": [...]
    },
    ...
  ],
  "output_format": {
    "results": [
      {
        "document_id": 0,
        "qa_pairs": [
          {"question": "...", "answer": "..."}
        ]
      },
      ...
    ]
  }
}
```

### å¿œç­”ãƒ‘ãƒ¼ã‚¹

```python
def _parse_batch_response(self, response) -> List[Dict]:
    """ãƒãƒƒãƒå¿œç­”ã®ãƒ‘ãƒ¼ã‚¹"""
    content = response.choices[0].message.content
    parsed = json.loads(content)

    results = []
    tokens_per_doc = response.usage.total_tokens // len(parsed.get("results", [1]))

    for doc_result in parsed.get("results", []):
        results.append({
            "qa_pairs": doc_result.get("qa_pairs", []),
            "tokens_used": tokens_per_doc
        })

    return results
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

### å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆï¼ˆ497æ–‡æ›¸ã®å ´åˆï¼‰

| å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ | APIå‘¼å‡ºæ•° | å‡¦ç†æ™‚é–“ | ã‚³ã‚¹ãƒˆï¼ˆgpt-5-miniï¼‰ | å‰Šæ¸›ç‡ |
|-----------|----------|---------|-------------------|--------|
| **é€šå¸¸ç‰ˆ** | 1,491å› | 3åˆ† | $0.075 | - |
| **ãƒãƒƒãƒç‰ˆï¼ˆ10ï¼‰** | 150å› | 1åˆ† | $0.008 | **89.9%** |
| **ãƒãƒƒãƒç‰ˆï¼ˆ20ï¼‰** | 75å› | 45ç§’ | $0.004 | **95.0%** |
| **ãƒãƒƒãƒç‰ˆï¼ˆ50ï¼‰** | 30å› | 30ç§’ | $0.002 | **98.0%** |

### ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£

| æ–‡æ›¸æ•° | é€šå¸¸ç‰ˆAPIå‘¼å‡º | ãƒãƒƒãƒç‰ˆAPIå‘¼å‡ºï¼ˆ10ï¼‰ | å‰Šæ¸›ç‡ |
|-------|-------------|-------------------|--------|
| 10 | 30å› | 4å› | 86.7% |
| 100 | 300å› | 30å› | 90.0% |
| 500 | 1,500å› | 150å› | 90.0% |
| 1,000 | 3,000å› | 300å› | 90.0% |
| 10,000 | 30,000å› | 3,000å› | 90.0% |

**çµè«–**: ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é–¢ã‚ã‚‰ãš**ç´„90%ã®å‰Šæ¸›ç‡**ã‚’ç¶­æŒ

---

## å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
qa_output/a10/  â­NEW
â”œâ”€â”€ batch_summary_{dataset}_{model}_b{batch_size}_{timestamp}.json      # ã‚µãƒãƒªãƒ¼
â””â”€â”€ batch_qa_pairs_{dataset}_{model}_b{batch_size}_{timestamp}.csv     # Q&Aãƒšã‚¢
```

### ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```json
{
    "dataset_type": "cc_news",
    "dataset_name": "CC-Newsè‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹",
    "model_used": "gpt-5-mini",
    "batch_processing": true,
    "batch_sizes": {
        "llm_batch_size": 10,
        "embedding_batch_size": 100
    },
    "documents_processed": 497,
    "total_qa_generated": 1491,
    "avg_qa_per_doc": 3.0,
    "processing_time": {
        "total_seconds": 60,
        "minutes": 1.0,
        "docs_per_second": 8.28
    },
    "api_usage": {
        "total_cost": 0.0075,
        "cost_per_doc": 0.000015,
        "batch_statistics": {
            "llm_batches": 50,
            "embedding_batches": 5,
            "total_llm_calls": 50,
            "total_embedding_calls": 5,
            "reduction_rate": 96.3
        }
    },
    "coverage": {
        "calculated": true,
        "avg_coverage": 85.5,
        "min_coverage": 72.0,
        "max_coverage": 95.0
    },
    "generation_timestamp": "2025-10-23T14:30:00"
}
```

---

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š

### å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | è¨€èª | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ–‡æ›¸ã‚¿ã‚¤ãƒ— |
|------------|-------------|------|------------------|
| cc_news | OUTPUT/preprocessed_cc_news.csv | è‹±èª | news |
| japanese_text | OUTPUT/preprocessed_japanese_text.csv | æ—¥æœ¬èª | auto |
| wikipedia_ja | OUTPUT/preprocessed_wikipedia_ja.csv | æ—¥æœ¬èª | academic |

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### Q: ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒé »ç™ºã™ã‚‹
**A:** ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
```bash
python a10_qa_optimized_hybrid_batch.py --batch-size 5
```

#### Q: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
**A:** åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
```bash
python a10_qa_optimized_hybrid_batch.py --embedding-batch-size 50
```

#### Q: API Rate Limit ã‚¨ãƒ©ãƒ¼
**A:** ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããã—ã¦å‘¼å‡ºé »åº¦ã‚’æ¸›ã‚‰ã™
```bash
python a10_qa_optimized_hybrid_batch.py --batch-size 20
```

#### Q: ãƒ‘ãƒ¼ã‚¹ ã‚¨ãƒ©ãƒ¼
**A:** ãƒ¢ãƒ‡ãƒ«ãŒJSONå½¢å¼ã‚’è¿”ã•ãªã„å ´åˆã€å€‹åˆ¥å‡¦ç†ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

#### Q: çµ±è¨ˆãŒè¡¨ç¤ºã•ã‚Œãªã„
**A:** `show_progress=True`ã‚’æŒ‡å®š
```python
results = generator.generate_batch_hybrid_qa(..., show_progress=True)
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã®é¸æŠ

| ç”¨é€” | æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º | ç†ç”± |
|------|---------------|------|
| **é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ** | 5 | ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®å½±éŸ¿æœ€å°åŒ– |
| **æœ¬ç•ªé‹ç”¨** | 10-20 | ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ |
| **å¤§é‡å‡¦ç†** | 20-50 | æœ€å¤§åŠ¹ç‡åŒ–ï¼ˆãƒªã‚¹ã‚¯å¢—ï¼‰ |
| **é«˜å“è³ªé‡è¦–** | 5-10 | ãƒ‘ãƒ¼ã‚¹ç²¾åº¦å‘ä¸Š |

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
# ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
try:
    # ãƒãƒƒãƒå‡¦ç†
    results = generator.generate_batch_hybrid_qa(texts, batch_size=20)
except Exception as e:
    logger.warning(f"ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {e}. å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
    # å€‹åˆ¥å‡¦ç†
    results = [generator.generate_hybrid_qa(text) for text in texts]
```

### 3. ã‚³ã‚¹ãƒˆæœ€é©åŒ–

```bash
# æœ€å°ã‚³ã‚¹ãƒˆã§ã®å¤§é‡å‡¦ç†
python a10_qa_optimized_hybrid_batch.py \
    --dataset cc_news \
    --model gpt-5-mini \
    --batch-size 50 \
    --no-coverage
```

### 4. å“è³ªé‡è¦–ã®è¨­å®š

```bash
# é«˜å“è³ªãƒ»ä½é€Ÿè¨­å®š
python a10_qa_optimized_hybrid_batch.py \
    --dataset cc_news \
    --model gpt-4o \
    --batch-size 5 \
    --qa-count 8
```

---

## æ¯”è¼ƒå®Ÿé¨“æ©Ÿèƒ½

### é€šå¸¸ç‰ˆ vs ãƒãƒƒãƒç‰ˆã®æ€§èƒ½æ¯”è¼ƒ

```bash
python a10_qa_optimized_hybrid_batch.py --dataset cc_news --compare --compare-size 10
```

**å‡ºåŠ›ä¾‹:**
```
================================================================================
ğŸ“Š æ€§èƒ½æ¯”è¼ƒçµæœ
================================================================================
ã‚µãƒ³ãƒ—ãƒ«æ•°: 10æ–‡æ›¸

ã€é€šå¸¸ç‰ˆï¼ˆå€‹åˆ¥å‡¦ç†ï¼‰ã€‘
  å‡¦ç†æ™‚é–“: 30.00ç§’
  APIå‘¼å‡º: 30å›
  1æ–‡æ›¸ã‚ãŸã‚Š: 3.00ç§’, 3.0å›

ã€ãƒãƒƒãƒç‰ˆï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰ã€‘
  å‡¦ç†æ™‚é–“: 10.00ç§’
  APIå‘¼å‡º: 3å›
  1æ–‡æ›¸ã‚ãŸã‚Š: 1.00ç§’, 0.3å›

ã€æ”¹å–„åŠ¹æœã€‘
  å‡¦ç†æ™‚é–“çŸ­ç¸®: 66.7%
  APIå‘¼å‡ºå‰Šæ¸›: 90.0%
  é«˜é€ŸåŒ–: 3.00x
================================================================================
```

---

## å¾“æ¥ç‰ˆã¨ã®äº’æ›æ€§

### ç§»è¡Œã‚¬ã‚¤ãƒ‰

```python
# å¾“æ¥ç‰ˆï¼ˆa10_qa_optimized_hybrid.pyï¼‰
from helper_rag_qa import OptimizedHybridQAGenerator

generator = OptimizedHybridQAGenerator()
results = []
for text in texts:
    result = generator.generate_hybrid_qa(text)
    results.append(result)

# ãƒãƒƒãƒç‰ˆï¼ˆäº’æ›æ€§ã‚ã‚Šï¼‰
from helper_rag_qa import BatchHybridQAGenerator

generator = BatchHybridQAGenerator()
results = generator.generate_batch_hybrid_qa(texts)  # ä¸€æ‹¬å‡¦ç†
```

### å‡ºåŠ›å½¢å¼ã®äº’æ›æ€§

ãƒãƒƒãƒç‰ˆã¯é€šå¸¸ç‰ˆã¨**å®Œå…¨ã«äº’æ›æ€§ã®ã‚ã‚‹**å‡ºåŠ›å½¢å¼ã‚’è¿”ã—ã¾ã™ï¼š

```python
# ä¸¡æ–¹ã¨ã‚‚åŒã˜æ§‹é€ 
result = {
    "qa_pairs": [...],
    "metadata": {...},
    "coverage": {...},
    "api_usage": {...}
}
```

---

## æŠ€è¡“çš„è©³ç´°

### ãƒãƒƒãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

```python
def _create_batch_prompt(self, texts, rule_results, doc_type):
    """ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
    documents = []
    for i, (text, rule_result) in enumerate(zip(texts, rule_results)):
        doc_info = {
            "document_id": i,
            "text": text[:1000],  # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™
            "keywords": rule_result.get("suggested_qa_pairs", [])[:5]
        }
        documents.append(doc_info)

    prompt = f"""Process these {len(documents)} documents...

    IMPORTANT: Return your response in JSON format.

    Output format (JSON):
    {{
        "results": [
            {{"document_id": 0, "qa_pairs": [...]}}
        ]
    }}"""

    return prompt
```

### æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‹•çš„åˆ¶å¾¡

```python
# gpt-5-miniãªã©ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã¯æ¸©åº¦éå¯¾å¿œ
api_params = {
    "model": self.model,
    "messages": [...],
    "response_format": {"type": "json_object"}
}

# æ¸©åº¦å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
if self.model not in self.no_temperature_models:
    api_params["temperature"] = 0.7
```

---

## ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ä¸€è¦§

| å¼•æ•° | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | é¸æŠè‚¢ | èª¬æ˜ |
|-----|-----|----------|-------|------|
| `--dataset` | str | cc_news | cc_news, japanese_text, wikipedia_ja | å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ |
| `--model` | str | gpt-5-mini | - | ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ« |
| `--batch-size` | int | 10 | - | LLMãƒãƒƒãƒã‚µã‚¤ã‚º |
| `--embedding-batch-size` | int | 100 | - | åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒã‚µã‚¤ã‚º |
| `--max-docs` | int | None | - | å‡¦ç†ã™ã‚‹æœ€å¤§æ–‡æ›¸æ•° |
| `--qa-count` | int | None | - | æ–‡æ›¸ã‚ãŸã‚Šã®Q/Aæ•° |
| `--doc-type` | str | None | news, technical, academic, auto | æ–‡æ›¸ã‚¿ã‚¤ãƒ— |
| `--no-llm` | flag | False | - | LLMã‚’ä½¿ç”¨ã—ãªã„ |
| `--no-coverage` | flag | False | - | ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®—ã‚’è¡Œã‚ãªã„ |
| `--output` | str | qa_output | - | å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
| `--compare` | flag | False | - | é€šå¸¸ç‰ˆã¨ã®æ¯”è¼ƒå®Ÿè¡Œ |
| `--compare-size` | int | 10 | - | æ¯”è¼ƒå®Ÿè¡Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º |

---

## ä»Šå¾Œã®æ”¹å–„è¨ˆç”»

1. **éåŒæœŸãƒãƒƒãƒå‡¦ç†**
   - asyncio ã«ã‚ˆã‚‹ä¸¦åˆ—å‡¦ç†
   - å‡¦ç†æ™‚é–“ã®ã•ã‚‰ãªã‚‹çŸ­ç¸®

2. **å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´**
   - æ–‡æ›¸é•·ã«å¿œã˜ãŸè‡ªå‹•èª¿æ•´
   - ã‚¨ãƒ©ãƒ¼ç‡ã«åŸºã¥ãé©å¿œåˆ¶å¾¡

3. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½**
   - åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
   - é‡è¤‡æ–‡æ›¸ã®æ¤œå‡ºã¨å†åˆ©ç”¨

4. **ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½**
   - æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
   - éƒ¨åˆ†çš„ãªæˆåŠŸã®ä¿å­˜

5. **é€²æ—çŠ¶æ…‹ã®æ°¸ç¶šåŒ–**
   - ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½
   - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜

---

## å¤‰æ›´å±¥æ­´

### v1.1 (2025-10-23)
- å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’`qa_output/a10/`ã«å¤‰æ›´ï¼ˆã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè‡ªå‹•ä½œæˆï¼‰
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨é¢æ›´æ–°ï¼ˆæœ€æ–°ä»•æ§˜ã‚’åæ˜ ï¼‰
- ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã®æ”¹å–„

### v1.0 (2025-10-21)
- ãƒãƒƒãƒå‡¦ç†ç‰ˆåˆç‰ˆãƒªãƒªãƒ¼ã‚¹
- BatchHybridQAGeneratorã‚¯ãƒ©ã‚¹å®Ÿè£…
- APIå‘¼å‡ºå‰Šæ¸›ç‡96%é”æˆ
- çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½è¿½åŠ 
- æ¯”è¼ƒå®Ÿé¨“æ©Ÿèƒ½å®Ÿè£…
- temperatureéå¯¾å¿œãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
- JSONå½¢å¼è¦ä»¶ã‚¨ãƒ©ãƒ¼ä¿®æ­£

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

[ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«æº–æ‹ ]

## ä½œæˆè€…

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯`a10_qa_optimized_hybrid.md`ã‚’å‚è€ƒã«ã€ãƒãƒƒãƒå‡¦ç†ã®æŠ€è¡“è©³ç´°ã¨æ€§èƒ½æ”¹å–„ã‚’ä¸­å¿ƒã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚