
#### Query Construction（クエリ構築）
- 自然言語から構造化クエリへの変換
RAG では、検索先がリレーショナルデータベースやグラフDBなどの場合、自然言語の質問を直接投げてもデータを取得できません。そのため、質問を SQL や Cypher、メタデータフィルタといった適切なクエリ言語に変換します ￼。
- Text‑to‑SQL／Text‑to‑Cypher／メタデータフィルタ生成
LLM を使って「質問の意図 → スキーマ → 適切な WHERE 句やパラメータ」へと翻訳する手法が多数研究されています。たとえば自動生成した SQL をデータベースに直接問い合わせたり、GraphDB では Cypher クエリを生成して関連ノードを取得します ￼。
- 自己クエリ取得 (self‑querying) の活用
メタデータ付きのドキュメント検索では、LLM が質問からスキーマやタグを推定し、それに基づいたフィルタ（例：出版日・カテゴリ）を作成する「Self‑Query Retriever」などもあります。
- 目的
この段階の狙いは、自然言語の曖昧さを排除し、対象データソースで正確に検索できる形に変換することです。特に複雑な構造化データや多様なメタデータがある場合に必須となります。

#### Query Translation（クエリ変換・翻訳）
- クエリの書き換え (Rewrite‑Retrieve‑Read)
ユーザーの質問が必ずしも検索に適しているとは限りません。LLM で質問をより明確・具体的に書き換えてから検索すると、関連文書を多く取得できることが実証されています ￼。
- Step‑Back Prompting（高レベル質問生成）
元の質問とは別に「一段階上の問い」を生成し、その回答から文脈を掴んで再検索する手法です。元の質問と step‑back 質問の双方で文書を取得して統合します ￼。
- Follow‑up question rewriting
会話型システムでは、フォローアップ質問を 文脈を含んだスタンドアローン質問に書き換えることで誤解を防ぎます ￼。
- Multi‑Query Retrieval／RAG‑Fusion
LLM で同じ質問の言い換えやサブ質問を複数生成し、それぞれで検索して結果を統合・再ランクする「Multi‑Query Retrieval」や、検索結果を相互順位付けする「RAG‑Fusion」 ￼。これにより、多角的な観点から関連文書を集められます。
- Query Expansion（HyDE など）
質問に対する仮想的な答え（Hypothetical Document Embedding）を生成したり、関連キーワードを付加することで検索範囲を広げる手法もあります ￼。
- 目的
クエリ翻訳の本質は、「ユーザーの曖昧な質問」→「検索エンジンが理解しやすい形」へ変換し、抜け漏れなく関連情報を取得することにあります。また、マルチクエリ生成や高レベル質問によって、複数の観点や潜在意図を反映させることができます。

#### Routing（ルーティング）
- 複数データソースへの振り分け
大規模な RAG システムでは、社内のチャット、基準文書、コードベース、外部ナレッジベースなど、複数のインデックスやデータベースを持つことが一般的です。すべてを一つの巨大インデックスにまとめるとアクセス制御や検索精度に悪影響があるため、クエリを適切なデータソースにルーティングする仕組みが重要になります ￼。
- フル・マルチプレクシング
もっとも単純な方法は、すべての関連データソースに同じクエリを送り、結果を結合して再ランクする方式です。この手法では recall を高く保てますが、計算コストが大きくなります ￼。
- LLMベースのルーティング
もう一つの方法は、LLM や小さな分類モデルを用いて質問の種類を判定し、関連性の高いインデックスやデータベースにのみクエリを送る方式です ￼。例えば法務ドキュメント用・技術資料用などのカテゴリーに分類します。この際、データ分布やクエリパターンを観察してモデルを調整すること（キャリブレーション）が推奨されています。
- ベクトル検索とフィルタリングの注意点
ベクトル検索は近似最近傍法を用いるため、フィルタリングを前後で行うと recall が低下することがあります。事前にフィルタしてから検索する方法と、事後にフィルタする方法の双方にトレードオフがあり ￼、データ構造やクエリ特性に応じて設計を決める必要があります。
- 目的
適切なルーティングは、アクセス制御やスケーラビリティを保ちつつ高い検索精度を維持するために不可欠です。

#### Retrieval（検索）
- ベクトル／ハイブリッド検索
チャンク化した文書を埋め込みベクトルに変換し、ユーザーのクエリを同じベクトル空間で近傍検索するのが基本です。最近ではスパース表現（キーワードベース）と密ベクトルを組み合わせるハイブリッド検索も使われています。
- Multi‑Vector／Parent Document Retrieval
大きな文書を小さな「子チャンク」に細分し、それぞれを別個に埋め込む「マルチベクトル」手法があります。検索時は子チャンク同士の類似度で候補を見つけますが、回答に使う際は元の大きな「親文書」を返すため、より広い文脈を確保しつつ細粒度な検索が可能になります ￼。これはトピックの混在した文書で特に有効です。
- 階層的再検索
Parent Document Retriever に代表されるように、小さなチャンクで検索して大きなチャンクを返す階層型の検索を導入すると、埋め込みの精度と文脈の両方を改善できます ￼。
- 再ランクとフィードバック
ベクトル検索で上位 K 件を取得した後、クロスエンコーダや LLM を用いて関連度を再計算し順位付けする「再ランク」や、先に取得した文脈からクエリを再生成して再検索する「再検索（self‑retrieval）」も効果的です。
- 目的
この段階ではクエリに最も関連する文書をできるだけ漏れなく取得することが目標であり、チャンク設計・埋め込み手法・検索アルゴリズムの選定が鍵となります。

⸻

#### その他の手法・改良点（例）
- Query Decomposition：長い複合質問を複数のサブクエリに分解して個別に検索し、結果を統合する手法。複雑な推論を要する問いに有効。
- Hypothetical Document Embedding (HyDE)：LLM に質問の仮想回答を生成させ、その回答文を埋め込んで検索することで高関連文書を取得する技術。
- Hybrid Retrieval：TF‑IDF などのスパース検索と密ベクトル検索を統合する方式。キーワードと意味検索の長所を両取りできる。
- Recursive Retrieval / Self‑Retrieval：初回検索で得た文脈を使ってクエリを更新し、二段階で検索する手法。
- データ正規化と評価基盤：チャンクサイズ・オーバーラップ・Top‑K などを変えながら RAG の挙動を測定することも重要。
- メタデータ利用とフィルタリング：ドメインや権限情報などで検索対象を絞り込む。
- 長文・多言語対応：長文向けには階層要約とロングコンテキストモデル、多言語対応では多言語埋め込みモデルや機械翻訳との組み合わせが挙げられます。

