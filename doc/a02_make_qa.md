# a02_make_qa.py - è©³ç´°è¨­è¨ˆæ›¸

## ç›®æ¬¡

1. [æ¦‚è¦](#1-æ¦‚è¦)
   - 1.1 [ç›®çš„](#11-ç›®çš„)
   - 1.2 [ä¸»è¦æ©Ÿèƒ½](#12-ä¸»è¦æ©Ÿèƒ½)
   - 1.3 [å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](#13-å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)
2. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#2-ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
   - 2.1 [ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³](#21-ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³)
   - 2.2 [ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ](#22-ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ)
3. [ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ•ãƒ­ãƒ¼](#3-ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ•ãƒ­ãƒ¼)
   - 3.1 [ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†](#31-ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å‰å‡¦ç†)
   - 3.2 [ãƒãƒ£ãƒ³ã‚¯ä½œæˆ](#32-ãƒãƒ£ãƒ³ã‚¯ä½œæˆ)
   - 3.3 [ãƒãƒ£ãƒ³ã‚¯çµ±åˆ](#33-ãƒãƒ£ãƒ³ã‚¯çµ±åˆ)
4. [Q/Aãƒšã‚¢ç”Ÿæˆ](#4-qaãƒšã‚¢ç”Ÿæˆ)
   - 4.1 [Q/Aæ•°æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯](#41-qaæ•°æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯)
   - 4.2 [ãƒãƒƒãƒå‡¦ç†ï¼ˆ3ãƒãƒ£ãƒ³ã‚¯åŒæ™‚ï¼‰](#42-ãƒãƒƒãƒå‡¦ç†3ãƒãƒ£ãƒ³ã‚¯åŒæ™‚)
   - 4.3 [å˜ä¸€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†](#43-å˜ä¸€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†)
   - 4.4 [ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®ç”Ÿæˆåˆ¶å¾¡](#44-ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®ç”Ÿæˆåˆ¶å¾¡)
5. [ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ](#5-ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ)
   - 5.1 [ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®—](#51-ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®—)
6. [çµæœä¿å­˜](#6-çµæœä¿å­˜)
   - 6.1 [save_results](#61-save_resultsqa_pairs-coverage_results-dataset_type-output_dir---dictstr-str)
7. [ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°](#7-ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°)
   - 7.1 [å¿…é ˆå¼•æ•°](#71-å¿…é ˆå¼•æ•°)
   - 7.2 [ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°](#72-ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°)
   - 7.3 [ä½¿ç”¨ä¾‹](#73-ä½¿ç”¨ä¾‹)
8. [ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼](#8-ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼)
   - 8.1 [main()é–¢æ•°ã®å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—](#81-mainé–¢æ•°ã®å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—)
   - 8.2 [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#82-ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
9. [ä¾å­˜é–¢ä¿‚](#9-ä¾å­˜é–¢ä¿‚)
   - 9.1 [å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª](#91-å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
   - 9.2 [å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«](#92-å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«)
10. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#10-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
    - 10.1 [APIå‘¼ã³å‡ºã—å‰Šæ¸›](#101-apiå‘¼ã³å‡ºã—å‰Šæ¸›)
    - 10.2 [ã‚¨ãƒ©ãƒ¼å›å¾©](#102-ã‚¨ãƒ©ãƒ¼å›å¾©)
    - 10.3 [ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–](#103-ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–)
11. [å‡ºåŠ›çµ±è¨ˆæƒ…å ±](#11-å‡ºåŠ›çµ±è¨ˆæƒ…å ±)
    - 11.1 [è³ªå•ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ](#111-è³ªå•ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ)
    - 11.2 [ã‚«ãƒãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ](#112-ã‚«ãƒãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ)
12. [æ³¨æ„äº‹é …ãƒ»åˆ¶ç´„](#12-æ³¨æ„äº‹é …åˆ¶ç´„)
    - 12.1 [åˆ¶ç´„äº‹é …](#121-åˆ¶ç´„äº‹é …)
    - 12.2 [æ¨å¥¨è¨­å®š](#122-æ¨å¥¨è¨­å®š)
    - 12.3 [ã‚³ã‚¹ãƒˆç®¡ç†](#123-ã‚³ã‚¹ãƒˆç®¡ç†)
13. [ä»Šå¾Œã®æ”¹å–„æ¡ˆ](#13-ä»Šå¾Œã®æ”¹å–„æ¡ˆ)
    - 13.1 [æ©Ÿèƒ½æ‹¡å¼µ](#131-æ©Ÿèƒ½æ‹¡å¼µ)
    - 13.2 [æœ€é©åŒ–](#132-æœ€é©åŒ–)
    - 13.3 [å“è³ªå‘ä¸Š](#133-å“è³ªå‘ä¸Š)

---

## 1. æ¦‚è¦

### 1.1 ç›®çš„
preprocessedãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰OpenAI APIã‚’ä½¿ç”¨ã—ã¦Q/Aãƒšã‚¢ã‚’è‡ªå‹•ç”Ÿæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã‚’åˆ†æã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚

### 1.2 ä¸»è¦æ©Ÿèƒ½
- preprocessed CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
- æ–‡æ›¸ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
- ãƒãƒ£ãƒ³ã‚¯ã®çµ±åˆæœ€é©åŒ–ï¼ˆ--merge-chunksï¼‰
- ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹Q/Aãƒšã‚¢ç”Ÿæˆï¼ˆ1-5ãƒãƒ£ãƒ³ã‚¯åŒæ™‚å‡¦ç†å¯¾å¿œã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
- **å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æï¼ˆstrict/standard/lenientï¼‰**
- **ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æï¼ˆé•·ã•åˆ¥ãƒ»ä½ç½®åˆ¥ã‚«ãƒãƒ¬ãƒ¼ã‚¸ï¼‰**
- çµæœã®JSON/CSVå½¢å¼ã§ã®ä¿å­˜ï¼ˆ4ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ï¼‰

### 1.3 å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | è¨€èª | ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º | Q/Aãƒšã‚¢æ•°/ãƒãƒ£ãƒ³ã‚¯ |
|------------|-------------|------|--------------|------------------|
| cc_news | OUTPUT/preprocessed_cc_news.csv | è‹±èª | 300ãƒˆãƒ¼ã‚¯ãƒ³ | 3 |
| japanese_text | OUTPUT/preprocessed_japanese_text.csv | æ—¥æœ¬èª | 200ãƒˆãƒ¼ã‚¯ãƒ³ | 2 |
| wikipedia_ja | OUTPUT/preprocessed_wikipedia_ja.csv | æ—¥æœ¬èª | 250ãƒˆãƒ¼ã‚¯ãƒ³ | 3 |

## 2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 2.1 ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**

1. preprocessed CSVèª­ã¿è¾¼ã¿
2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å‡¦ç†
3. ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
4. ãƒãƒ£ãƒ³ã‚¯çµ±åˆï¼ˆå°ã•ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒ¼ã‚¸ï¼‰
5. ãƒãƒƒãƒå‡¦ç†ã§Q/Aç”Ÿæˆï¼ˆOpenAI API: responses.parseä½¿ç”¨ï¼‰
6. ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦è¨ˆç®—ï¼‰
7. çµæœä¿å­˜
8. JSON/CSVå‡ºåŠ›

### 2.2 ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 2.2.1 ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆPydanticï¼‰
- **QAPair**: å€‹åˆ¥Q/Aãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
  - question: str - è³ªå•æ–‡
  - answer: str - å›ç­”æ–‡
  - question_type: str - è³ªå•ã‚¿ã‚¤ãƒ—ï¼ˆfact/reason/comparison/applicationï¼‰
  - source_chunk_id: Optional[str] - ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒ³ã‚¯ID
  - dataset_type: Optional[str] - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¨®åˆ¥
  - auto_generated: bool - è‡ªå‹•ç”Ÿæˆãƒ•ãƒ©ã‚°

- **QAPairsResponse**: APIå¿œç­”ç”¨ãƒ¢ãƒ‡ãƒ«
  - qa_pairs: List[QAPair] - Q/Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆ

#### 2.2.2 è¨­å®šç®¡ç†
- **DATASET_CONFIGS**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥è¨­å®šè¾æ›¸
  - name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
  - file: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
  - text_column: ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ å
  - title_column: ã‚¿ã‚¤ãƒˆãƒ«ã‚«ãƒ©ãƒ åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  - lang: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ"ja" or "en"ï¼‰
  - chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰
  - qa_per_chunk: ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®Q/Aãƒšã‚¢æ•°

## 3. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ•ãƒ­ãƒ¼

### 3.1 ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†

#### load_preprocessed_data(dataset_type: str) -> pd.DataFrame
**ç›®çš„**: preprocessed CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’å®Ÿè¡Œ

**å‡¦ç†æ‰‹é †**:
1. DATASET_CONFIGSã‹ã‚‰è¨­å®šå–å¾—
2. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
3. CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
4. å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ç¢ºèª
5. ç©ºãƒ†ã‚­ã‚¹ãƒˆé™¤å¤–
6. DataFrameã‚’è¿”å´

**ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**:
- æœªå¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: ValueError
- ãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨: FileNotFoundError
- ã‚«ãƒ©ãƒ ä¸åœ¨: ValueError

### 3.2 ãƒãƒ£ãƒ³ã‚¯ä½œæˆ

#### create_document_chunks(df: pd.DataFrame, dataset_type: str, max_docs: Optional[int]) -> List[Dict]
**ç›®çš„**: DataFrameã‹ã‚‰æ–‡æ›¸ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ

**å‡¦ç†æ‰‹é †**:
1. è¨­å®šæƒ…å ±å–å¾—ï¼ˆtext_column, title_column, chunk_sizeï¼‰
2. SemanticCoverageã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
3. å‡¦ç†æ–‡æ›¸æ•°åˆ¶é™ï¼ˆmax_docsãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
4. å„æ–‡æ›¸ã‚’åå¾©å‡¦ç†:
   - ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆstrå‹ã«å¤‰æ›ï¼‰
   - doc_idç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«å«ã‚€å ´åˆã¯å…ˆé ­30æ–‡å­—ï¼‰
   - SemanticCoverage.create_semantic_chunksã§ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ ï¼ˆdoc_id, doc_idx, chunk_idx, dataset_typeï¼‰
5. å…¨ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã‚’è¿”å´

**æ³¨æ„äº‹é …**:
- create_semantic_chunksã¯å†…éƒ¨ã§200ãƒˆãƒ¼ã‚¯ãƒ³å›ºå®šã‚’ä½¿ç”¨ï¼ˆè¨­å®šã®chunk_sizeã¯åæ˜ ã•ã‚Œãªã„ï¼‰
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯è­¦å‘Šãƒ­ã‚°å‡ºåŠ›ã—ã¦continue

### 3.3 ãƒãƒ£ãƒ³ã‚¯çµ±åˆ

#### merge_small_chunks(chunks: List[Dict], min_tokens: int = 150, max_tokens: int = 400) -> List[Dict]
**ç›®çš„**: å°ã•ã„ãƒãƒ£ãƒ³ã‚¯ã‚’çµ±åˆã—ã¦é©åˆ‡ãªã‚µã‚¤ã‚ºã«æœ€é©åŒ–

**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:
1. tiktokenï¼ˆcl100k_baseï¼‰ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆ
2. å„ãƒãƒ£ãƒ³ã‚¯ã‚’åå¾©:
   - ãƒˆãƒ¼ã‚¯ãƒ³æ•° >= min_tokens â†’ ãã®ã¾ã¾è¿½åŠ 
   - ãƒˆãƒ¼ã‚¯ãƒ³æ•° < min_tokens â†’ çµ±åˆå€™è£œ
3. çµ±åˆæ¡ä»¶:
   - çµ±åˆå¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³æ•° <= max_tokens
   - åŒä¸€æ–‡æ›¸ï¼ˆdoc_idä¸€è‡´ï¼‰ã‹ã‚‰ã®ãƒãƒ£ãƒ³ã‚¯
4. çµ±åˆæ™‚ã®å‡¦ç†:
   - ãƒ†ã‚­ã‚¹ãƒˆã‚’"\n\n"ã§é€£çµ
   - original_chunksãƒªã‚¹ãƒˆã«å…ƒãƒãƒ£ãƒ³ã‚¯IDã‚’è¨˜éŒ²
   - chunk_idxã‚’ç¯„å›²å½¢å¼ã§è¨˜éŒ²ï¼ˆä¾‹: "0-2"ï¼‰
5. çµ±åˆãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã‚’è¿”å´

**åŠ¹æœ**:
- APIå‘¼ã³å‡ºã—å›æ•°å‰Šæ¸›
- ã‚³ã‚¹ãƒˆå‰Šæ¸›
- æ–‡è„ˆã®é€£ç¶šæ€§å‘ä¸Š

## 4. Q/Aãƒšã‚¢ç”Ÿæˆ

### 4.1 Q/Aæ•°æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯

#### determine_qa_count(chunk: Dict, config: Dict) -> int
**ç›®çš„**: ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«åŸºã¥ã„ã¦æœ€é©ãªQ/Aæ•°ã‚’æ±ºå®š

**ãƒ­ã‚¸ãƒƒã‚¯**:
| ãƒˆãƒ¼ã‚¯ãƒ³æ•°ç¯„å›² | Q/Aæ•° |
|--------------|-------|
| < 50 | min(base_count, 1) |
| 50-99 | min(base_count, 2) |
| 100-199 | base_count |
| >= 200 | min(base_count + 1, 5) |

### 4.2 ãƒãƒƒãƒå‡¦ç†ï¼ˆ3ãƒãƒ£ãƒ³ã‚¯åŒæ™‚ï¼‰

#### generate_qa_pairs_for_batch(chunks: List[Dict], config: Dict, model: str, client: OpenAI) -> List[Dict]
**ç›®çš„**: è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ï¼ˆæœ€å¤§3å€‹ï¼‰ã‹ã‚‰ä¸€åº¦ã«Q/Aãƒšã‚¢ã‚’ç”Ÿæˆ

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
1. ãƒãƒ£ãƒ³ã‚¯æ•°ãƒã‚§ãƒƒã‚¯:
   - 0å€‹: ç©ºãƒªã‚¹ãƒˆè¿”å´
   - 1å€‹: generate_qa_pairs_for_chunk()ã¸å§”è­²
   - 2å€‹ä»¥ä¸Š: ãƒãƒƒãƒå‡¦ç†ç¶™ç¶š

2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆè¨€èªåˆ¥ï¼‰:
   - æ—¥æœ¬èªã®å ´åˆ:
     - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆå°‚é–€å®¶
     - è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ãƒ†ã‚­ã‚¹ãƒˆ1ã€‘ã€ãƒ†ã‚­ã‚¹ãƒˆ2ã€‘...ã§çµåˆ
     - å„ãƒãƒ£ãƒ³ã‚¯ã®Q/Aæ•°ã‚’è¨ˆç®—ã—åˆè¨ˆã‚’æŒ‡ç¤º
   - è‹±èªã®å ´åˆ: åŒæ§˜ã®æ§‹é€ ã‚’è‹±èªã§æ§‹ç¯‰

3. OpenAI APIå‘¼ã³å‡ºã—:
   ```python
   response = client.responses.parse(
       input=combined_input,
       model=model,
       text_format=QAPairsResponse,
       max_output_tokens=4000
   )
   ```

4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ:
   - parsed_dataã‹ã‚‰Q/Aãƒšã‚¢ã‚’å–å¾—
   - å„ãƒãƒ£ãƒ³ã‚¯ã«æœŸå¾…ã•ã‚Œã‚‹æ•°ã ã‘Q/Aã‚’é †æ¬¡å‰²ã‚Šå½“ã¦
   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ ï¼ˆsource_chunk_id, doc_id, dataset_type, chunk_idxï¼‰

5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°:
   - ä¾‹å¤–ç™ºç”Ÿæ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§å€‹åˆ¥å‡¦ç†

### 4.3 å˜ä¸€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†

#### generate_qa_pairs_for_chunk(chunk: Dict, config: Dict, model: str, client: OpenAI) -> List[Dict]
**ç›®çš„**: å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰Q/Aãƒšã‚¢ã‚’ç”Ÿæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ç¶­æŒï¼‰

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
1. Q/Aæ•°æ±ºå®šï¼ˆdetermine_qa_countï¼‰
2. è¨€èªåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰:
   - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ç”Ÿæˆãƒ«ãƒ¼ãƒ«æŒ‡ç¤º
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ãƒ†ã‚­ã‚¹ãƒˆ + è³ªå•ã‚¿ã‚¤ãƒ— + JSONå½¢å¼æŒ‡ç¤º
3. ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™:
   - 2000æ–‡å­—è¶…ã®å ´åˆã¯åˆ‡ã‚Šè©°ã‚
4. APIå‘¼ã³å‡ºã—ï¼ˆresponses.parseä½¿ç”¨ï¼‰
5. ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸

**è³ªå•ã‚¿ã‚¤ãƒ—**:
- fact: äº‹å®Ÿç¢ºèªå‹ï¼ˆWhat is...?ï¼‰
- reason: ç†ç”±èª¬æ˜å‹ï¼ˆWhy...?ï¼‰
- comparison: æ¯”è¼ƒå‹ï¼ˆWhat's the difference...?ï¼‰
- application: å¿œç”¨å‹ï¼ˆHow is... used?ï¼‰

### 4.4 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®ç”Ÿæˆåˆ¶å¾¡

#### generate_qa_for_dataset(chunks, dataset_type, model, chunk_batch_size, merge_chunks, min_tokens, max_tokens) -> List[Dict]
**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®Q/Aãƒšã‚¢ç”Ÿæˆã‚’çµ±æ‹¬

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
1. å‰å‡¦ç†:
   - merge_chunks=Trueã®å ´åˆã€merge_small_chunksã§çµ±åˆ
   - APIå‘¼ã³å‡ºã—å›æ•°è¨ˆç®—

2. ãƒãƒƒãƒå‡¦ç†ãƒ«ãƒ¼ãƒ—:
   ```python
   for i in range(0, total_chunks, chunk_batch_size):
       batch = processed_chunks[i:i+chunk_batch_size]
       # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãQ/Aç”Ÿæˆ
       for attempt in range(max_retries):
           # ç”Ÿæˆå®Ÿè¡Œ
   ```

3. ãƒªãƒˆãƒ©ã‚¤åˆ¶å¾¡:
   - æœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤
   - æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ2^attemptç§’å¾…æ©Ÿï¼‰
   - æœ€çµ‚å¤±æ•—æ™‚ã¯å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

4. APIåˆ¶é™å¯¾ç­–:
   - ãƒãƒƒãƒé–“ã§0.5ç§’å¾…æ©Ÿ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- chunk_batch_size: 1-5ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
- merge_chunks: boolï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
- min_tokens: çµ±åˆå¯¾è±¡æœ€å°ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 150ï¼‰
- max_tokens: çµ±åˆå¾Œæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 400ï¼‰

## 5. ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ

### 5.1 ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¨ˆç®—ï¼ˆå¤šæ®µéšåˆ†æå¯¾å¿œï¼‰

#### analyze_coverage(chunks: List[Dict], qa_pairs: List[Dict], dataset_type: str) -> Dict
**ç›®çš„**: ç”ŸæˆQ/Aãƒšã‚¢ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã‹åˆ†æ

**å‡¦ç†æ‰‹é †**:
1. åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ:
   - ãƒãƒ£ãƒ³ã‚¯åŸ‹ã‚è¾¼ã¿: SemanticCoverage.generate_embeddings()
   - Q/AåŸ‹ã‚è¾¼ã¿: è³ªå•+å›ç­”ã‚’çµåˆã—ã¦generate_embedding()

2. ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¡Œåˆ—è¨ˆç®—:
   ```python
   coverage_matrix = np.zeros((len(chunks), len(qa_pairs)))
   for i, j in itertools.product(range(len(chunks)), range(len(qa_pairs))):
       similarity = cosine_similarity(doc_embeddings[i], qa_embeddings[j])
       coverage_matrix[i, j] = similarity
   ```

3. **å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ¤å®šï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥æœ€é©é–¾å€¤ä½¿ç”¨ï¼‰**:
   - **cc_news**: strict(0.80) / standard(0.70) / lenient(0.60)
   - **japanese_text**: strict(0.75) / standard(0.65) / lenient(0.55)
   - **wikipedia_ja**: strict(0.85) / standard(0.75) / lenient(0.65)
   - å„é–¾å€¤ã§ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡ã‚’ç®—å‡º
   - é–¾å€¤ã”ã¨ã«æœªã‚«ãƒãƒ¼ãƒãƒ£ãƒ³ã‚¯ã¨ã‚®ãƒ£ãƒƒãƒ—ã‚’è¨˜éŒ²

4. **ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æ**:
   - **é•·ã•åˆ¥**: short(<100ãƒˆãƒ¼ã‚¯ãƒ³) / medium(100-200) / long(>=200)
     - å„ã‚«ãƒ†ã‚´ãƒªã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡ã¨å¹³å‡é¡ä¼¼åº¦ã‚’è¨ˆç®—
   - **ä½ç½®åˆ¥**: beginning(å‰åŠ33%) / middle(ä¸­ç›¤34%) / end(å¾ŒåŠ33%)
     - æ–‡æ›¸å†…ã§ã®ä½ç½®ã«ã‚ˆã‚‹ã‚«ãƒãƒ¬ãƒ¼ã‚¸å‚¾å‘ã‚’åˆ†æ
   - ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒ70%æœªæº€ã®ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ

**è¿”å´ãƒ‡ãƒ¼ã‚¿ï¼ˆæ‹¡å¼µç‰ˆï¼‰**:
```python
{
    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    "coverage_rate": float,           # standardé–¾å€¤ã§ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡
    "covered_chunks": int,
    "total_chunks": int,
    "uncovered_chunks": List[Dict],
    "max_similarities": List[float],
    "threshold": float,               # standardé–¾å€¤

    # å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸ï¼ˆæ–°è¦ï¼‰
    "multi_threshold": {
        "strict": {
            "threshold": 0.80,
            "covered_chunks": 40,
            "coverage_rate": 0.80,
            "uncovered_count": 10,
            "uncovered_chunks": [...]
        },
        "standard": {...},
        "lenient": {...}
    },

    # ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æï¼ˆæ–°è¦ï¼‰
    "chunk_analysis": {
        "by_length": {
            "short": {"count": 15, "covered": 12, "coverage_rate": 0.80, "avg_similarity": 0.75},
            "medium": {...},
            "long": {...}
        },
        "by_position": {
            "beginning": {"count": 17, "covered": 16, "coverage_rate": 0.94, "avg_similarity": 0.78},
            "middle": {...},
            "end": {...}
        },
        "summary": {
            "total_chunks": 50,
            "total_qa_pairs": 150,
            "threshold_used": 0.70,
            "insights": [
                "shortãƒãƒ£ãƒ³ã‚¯ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„ï¼ˆ65.0%ï¼‰",
                "æ–‡æ›¸endéƒ¨åˆ†ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„ï¼ˆ68.0%ï¼‰"
            ]
        }
    },

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
    "dataset_type": "cc_news",
    "optimal_thresholds": {"strict": 0.80, "standard": 0.70, "lenient": 0.60}
}
```

## 6. çµæœä¿å­˜

### 6.1 save_results(qa_pairs, coverage_results, dataset_type, output_dir) -> Dict[str, str]

**ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«**:
1. **Q/Aãƒšã‚¢ï¼ˆJSONï¼‰**: `qa_pairs_{dataset_type}_{timestamp}.json`
   - ensure_ascii=Falseï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
   - indent=2ï¼ˆå¯èª­æ€§å‘ä¸Šï¼‰

2. **Q/Aãƒšã‚¢ï¼ˆCSVï¼‰**: `qa_pairs_{dataset_type}_{timestamp}.csv`
   - pd.DataFrameã§å¤‰æ›
   - encoding='utf-8'

3. **ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æçµæœï¼ˆJSONï¼‰**: `coverage_{dataset_type}_{timestamp}.json`
   - uncovered_chunksã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆï¼ˆ200æ–‡å­—ã¾ã§ï¼‰

4. **ã‚µãƒãƒªãƒ¼ï¼ˆJSONï¼‰**: `summary_{dataset_type}_{timestamp}.json`
   ```json
   {
     "dataset_type": "cc_news",
     "dataset_name": "CC-Newsè‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹",
     "generated_at": "20241004_141030",
     "total_qa_pairs": 150,
     "coverage_rate": 0.85,
     "covered_chunks": 43,
     "total_chunks": 50,
     "files": {...}
   }
   ```

## 7. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°

### 7.1 å¿…é ˆå¼•æ•°
ãªã—ï¼ˆã™ã¹ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

### 7.2 ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°

| å¼•æ•° | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----|-----|----------|------|
| --dataset | str | cc_news | å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆcc_news/japanese_text/wikipedia_jaï¼‰ |
| --model | str | gpt-5-mini | ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ« |
| --output | str | qa_output | å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
| --max-docs | int | None | å‡¦ç†ã™ã‚‹æœ€å¤§æ–‡æ›¸æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰ |
| --analyze-coverage | flag | False | ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æã‚’å®Ÿè¡Œ |
| --batch-chunks | int | 3 | 1å›ã®APIã§å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯æ•°ï¼ˆ1-5ï¼‰ |
| --merge-chunks | flag | True | å°ã•ã„ãƒãƒ£ãƒ³ã‚¯ã‚’çµ±åˆã™ã‚‹ |
| --no-merge-chunks | flag | False | ãƒãƒ£ãƒ³ã‚¯çµ±åˆã‚’ç„¡åŠ¹åŒ– |
| --min-tokens | int | 150 | çµ±åˆå¯¾è±¡ã®æœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•° |
| --max-tokens | int | 400 | çµ±åˆå¾Œã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•° |

### 7.3 ä½¿ç”¨ä¾‹

```bash
# ã€æ¨å¥¨ã€‘æœ¬ç•ªé‹ç”¨è¨­å®šï¼ˆ100è¨˜äº‹ã€ãƒãƒƒãƒ3ã€20åˆ†ã€$0.15ï¼‰
python a02_make_qa.py --dataset cc_news --max-docs 100 --batch-chunks 3 --merge-chunks --model gpt-5-mini --analyze-coverage

# ã€æœ€åŠ¹ç‡ã€‘APIå‘¼ã³å‡ºã—æœ€å°åŒ–ï¼ˆãƒãƒƒãƒ5ï¼‰
python a02_make_qa.py --dataset cc_news --batch-chunks 5 --merge-chunks --analyze-coverage

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆ10æ–‡æ›¸ï¼‰
python a02_make_qa.py --dataset cc_news --model gpt-5-mini --analyze-coverage --max-docs 10

# Wikipediaæ—¥æœ¬èªç‰ˆã€ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æã‚ã‚Š
python a02_make_qa.py --dataset wikipedia_ja --model gpt-5-mini --analyze-coverage --max-docs 10

# æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã€å€‹åˆ¥å‡¦ç†ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ï¼‰
python a02_make_qa.py --dataset japanese_text --batch-chunks 1 --no-merge-chunks

# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ£ãƒ³ã‚¯çµ±åˆè¨­å®š
python a02_make_qa.py --min-tokens 100 --max-tokens 500 --batch-chunks 5
```

### 7.4 æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›

**100è¨˜äº‹å‡¦ç†æ™‚ã®ä¾‹ï¼ˆcc_newsã€batch-3ï¼‰:**
```
ç”ŸæˆQ/Aãƒšã‚¢æ•°: 525
å‡¦ç†æ™‚é–“: 15-20åˆ†
APIå‘¼ã³å‡ºã—: ç´„35-45å›
ã‚³ã‚¹ãƒˆ: $0.10-0.15 (gpt-5-mini)

ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«:
- Q/A (JSON): qa_output/qa_pairs_cc_news_20251020_143052.json
- Q/A (CSV): qa_output/qa_pairs_cc_news_20251020_143052.csv
- ã‚«ãƒãƒ¬ãƒ¼ã‚¸: qa_output/coverage_cc_news_20251020_143052.json
- ã‚µãƒãƒªãƒ¼: qa_output/summary_cc_news_20251020_143052.json
```

## 8. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼

### 8.1 main()é–¢æ•°ã®å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—

```
[1/4] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
  â†“
  load_preprocessed_data(args.dataset)
  â†“
[2/4] ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
  â†“
  create_document_chunks(df, args.dataset, args.max_docs)
  â†“
[3/4] Q/Aãƒšã‚¢ç”Ÿæˆ
  â†“
  generate_qa_for_dataset(chunks, ...)
  â†“
[4/4] ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  â†“
  analyze_coverage(chunks, qa_pairs)
  â†“
çµæœä¿å­˜
  â†“
  save_results(qa_pairs, coverage_results, ...)
  â†“
çµ±è¨ˆæƒ…å ±è¡¨ç¤º
```

### 8.2 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
1. **API Keyæœªè¨­å®š**:
   - ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYãƒã‚§ãƒƒã‚¯
   - "your-openai-api-key-here"ã‚‚ä¸æ­£ã¨åˆ¤å®š
   - sys.exit(1)ã§çµ‚äº†

2. **ãƒãƒ£ãƒ³ã‚¯ä½œæˆå¤±æ•—**:
   - ç©ºã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ â†’ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚° + sys.exit(1)

3. **Q/Aç”Ÿæˆå¤±æ•—**:
   - å€‹åˆ¥ãƒãƒ£ãƒ³ã‚¯ã‚¨ãƒ©ãƒ¼: è­¦å‘Šãƒ­ã‚°å‡ºåŠ›ã—ã¦ç¶™ç¶š
   - ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼: ãƒªãƒˆãƒ©ã‚¤ â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

4. **å…¨ä½“ã‚¨ãƒ©ãƒ¼**:
   - try-exceptã§ã‚­ãƒ£ãƒƒãƒ
   - traceback.print_exc()ã§è©³ç´°å‡ºåŠ›
   - sys.exit(1)

## 9. ä¾å­˜é–¢ä¿‚

### 9.1 å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **openai**: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆresponses.parseä½¿ç”¨ï¼‰
- **pandas**: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æ“ä½œ
- **numpy**: æ•°å€¤è¨ˆç®—ã€è¡Œåˆ—æ¼”ç®—
- **tiktoken**: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆcl100k_baseï¼‰
- **pydantic**: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©ãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- **python-dotenv**: ç’°å¢ƒå¤‰æ•°ç®¡ç†

### 9.2 å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- **rag_qa.SemanticCoverage**:
  - create_semantic_chunks(): ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
  - generate_embeddings(): åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆãƒãƒƒãƒï¼‰
  - generate_embedding(): åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆå˜ä¸€ï¼‰
  - cosine_similarity(): ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—

## 10. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 10.1 APIå‘¼ã³å‡ºã—å‰Šæ¸›
- **ãƒãƒ£ãƒ³ã‚¯çµ±åˆ**: å°ã•ã„ãƒãƒ£ãƒ³ã‚¯ã‚’çµ±åˆã—ã¦å‘¼ã³å‡ºã—å›æ•°å‰Šæ¸›
- **ãƒãƒƒãƒå‡¦ç†**: 3ãƒãƒ£ãƒ³ã‚¯åŒæ™‚å‡¦ç†ã§APIå‘¼ã³å‡ºã—1/3ã«å‰Šæ¸›
- **åŠ¹æœä¾‹**:
  - å…ƒ150ãƒãƒ£ãƒ³ã‚¯ â†’ çµ±åˆ100ãƒãƒ£ãƒ³ã‚¯ â†’ ãƒãƒƒãƒ34å›å‘¼ã³å‡ºã—
  - å¾“æ¥æ¯”: 150å› â†’ 34å›ï¼ˆç´„77%å‰Šæ¸›ï¼‰

### 10.2 ã‚¨ãƒ©ãƒ¼å›å¾©
- **æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•**: 2^attemptç§’å¾…æ©Ÿ
- **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: ãƒãƒƒãƒå¤±æ•—æ™‚ã¯å€‹åˆ¥å‡¦ç†
- **æœ€å¤§ãƒªãƒˆãƒ©ã‚¤**: 3å›

### 10.3 ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
- ãƒãƒƒãƒé–“0.5ç§’å¾…æ©Ÿ
- max_output_tokensåˆ¶å¾¡ï¼ˆå˜ä¸€: 1000ã€ãƒãƒƒãƒ: 4000ï¼‰

## 11. å‡ºåŠ›çµ±è¨ˆæƒ…å ±

### 11.1 è³ªå•ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
ç”Ÿæˆå®Œäº†å¾Œã€è³ªå•ã‚¿ã‚¤ãƒ—ã”ã¨ã®ä»¶æ•°ã‚’è¡¨ç¤º:
```
è³ªå•ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ:
  application: 45ä»¶
  comparison: 38ä»¶
  fact: 42ä»¶
  reason: 25ä»¶
```

### 11.2 ã‚«ãƒãƒ¬ãƒ¼ã‚¸çµ±è¨ˆï¼ˆå¤šæ®µéšåˆ†æå¯¾å¿œï¼‰
```
å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æçµæœ:
- Strict  (é–¾å€¤0.80): 80.0%
- Standard(é–¾å€¤0.70): 85.0%
- Lenient (é–¾å€¤0.60): 92.0%

ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥ã‚«ãƒãƒ¬ãƒ¼ã‚¸:
é•·ã•åˆ¥:
- Short ãƒãƒ£ãƒ³ã‚¯: 80.0%
- Medium ãƒãƒ£ãƒ³ã‚¯: 88.0%
- Long ãƒãƒ£ãƒ³ã‚¯: 85.0%

ä½ç½®åˆ¥:
- Beginning (å‰åŠ): 94.0%
- Middle (ä¸­ç›¤): 82.0%
- End (å¾ŒåŠ): 78.0%

ğŸ“Š åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆ:
  â€¢ æ–‡æ›¸endéƒ¨åˆ†ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„ï¼ˆ78.0%ï¼‰
```

## 12. æ³¨æ„äº‹é …ãƒ»åˆ¶ç´„

### 12.1 åˆ¶ç´„äº‹é …
1. **ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º**: create_semantic_chunksã¯å†…éƒ¨ã§200ãƒˆãƒ¼ã‚¯ãƒ³å›ºå®šï¼ˆè¨­å®šã®chunk_sizeã¯ä½¿ç”¨ã•ã‚Œãªã„ï¼‰
2. **ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™**:
   - å˜ä¸€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†: 2000æ–‡å­—ã¾ã§
   - ãƒãƒƒãƒå‡¦ç†ï¼ˆãƒãƒ£ãƒ³ã‚¯çµåˆæ™‚ï¼‰: 1000æ–‡å­—ã¾ã§
3. **ãƒãƒƒãƒã‚µã‚¤ã‚º**: æœ€å¤§5ãƒãƒ£ãƒ³ã‚¯ï¼ˆæ¨å¥¨: 3ã€æœ€åŠ¹ç‡: 5ï¼‰
4. **ã‚«ãƒãƒ¬ãƒ¼ã‚¸é–¾å€¤**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ã«è‡ªå‹•è¨­å®šï¼ˆOPTIMAL_THRESHOLDSï¼‰
   - ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ã®å¤‰æ›´ã¯ä¸å¯ï¼ˆå°†æ¥ã®æ”¹å–„äºˆå®šï¼‰

### 12.2 æ¨å¥¨è¨­å®š
- **æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**:
  - batch_chunks: 2-3ï¼ˆæ—¥æœ¬èªã¯é•·ããªã‚‹å‚¾å‘ï¼‰
  - min_tokens: 150, max_tokens: 400

- **è‹±èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**:
  - batch_chunks: 3-5
  - min_tokens: 100, max_tokens: 500

### 12.3 ã‚³ã‚¹ãƒˆç®¡ç†
- `--max-docs`ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ¨å¥¨
- ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´ã§APIå‘¼ã³å‡ºã—å‰Šæ¸›
- ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æã¯åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚³ã‚¹ãƒˆãŒè¿½åŠ ï¼ˆå¿…è¦æ™‚ã®ã¿å®Ÿè¡Œï¼‰

## 13. ä»Šå¾Œã®æ”¹å–„æ¡ˆ

### 13.1 æ©Ÿèƒ½æ‹¡å¼µ
1. ã‚«ãƒãƒ¬ãƒ¼ã‚¸é–¾å€¤ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°åŒ–
2. create_semantic_chunksã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®šã‹ã‚‰åˆ¶å¾¡
3. è³ªå•ã‚¿ã‚¤ãƒ—ã®é‡ã¿ä»˜ã‘è¨­å®š
4. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«åŒæ™‚å®Ÿè¡Œï¼ˆæ¯”è¼ƒç”¨ï¼‰

### 13.2 æœ€é©åŒ–
1. åŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹
2. ä¸¦åˆ—å‡¦ç†ï¼ˆasyncioå¯¾å¿œï¼‰
3. ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤ºï¼ˆtqdmå°å…¥ï¼‰
4. ä¸­é–“çµæœã®è‡ªå‹•ä¿å­˜ï¼ˆãƒ¬ã‚¸ãƒ¥ãƒ¼ãƒ æ©Ÿèƒ½ï¼‰

### 13.3 å“è³ªå‘ä¸Š
1. Q/Aãƒšã‚¢ã®è‡ªå‹•å“è³ªè©•ä¾¡
2. é‡è¤‡Q/Aã®æ¤œå‡ºãƒ»é™¤å»
3. é›£æ˜“åº¦åˆ¥ã®è³ªå•ç”Ÿæˆ
4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿæ§‹