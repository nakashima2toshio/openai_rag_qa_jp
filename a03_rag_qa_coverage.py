#!/usr/bin/env python3
"""
ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã¨Q/Aç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
helper_rag_qa.pyã®å…¨ã‚¯ãƒ©ã‚¹ã‚’æ´»ç”¨ã—ãŸåŒ…æ‹¬çš„ãªQ/Aç”Ÿæˆã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
python a03_rag_qa_coverage.py
"""

from helper_rag_qa import (
    SemanticCoverage,
    QAGenerationConsiderations,
    QAPair,
    QAPairsList,
    LLMBasedQAGenerator,
    ChainOfThoughtQAGenerator,
    RuleBasedQAGenerator,
    TemplateBasedQAGenerator,
    HybridQAGenerator,
    AdvancedQAGenerationTechniques,
    QAGenerationOptimizer,
)
import os
import json
from typing import List, Dict
import pprint

def qa_generation_checklist():
    """Q/Aç”Ÿæˆæ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ"""
    return {
        "äº‹å‰æº–å‚™"  : [
            "â–¡ æ–‡æ›¸ã®ç¨®é¡ã¨ç‰¹æ€§ã‚’åˆ†æ",
            "â–¡ ç›®çš„ï¼ˆè©•ä¾¡/å­¦ç¿’/ãƒ†ã‚¹ãƒˆï¼‰ã‚’æ˜ç¢ºåŒ–",
            "â–¡ å¿…è¦ãªã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š",
            "â–¡ äºˆç®—ã¨ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¢ºèª"
        ],
        "å“è³ªåŸºæº–"  : [
            "â–¡ å›ç­”ãŒãƒ†ã‚­ã‚¹ãƒˆå†…ã«å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª",
            "â–¡ è³ªå•ã®æ˜ç¢ºæ€§ã¨æ›–æ˜§ã•ã®æ’é™¤",
            "â–¡ è³ªå•ã‚¿ã‚¤ãƒ—ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿",
            "â–¡ é›£æ˜“åº¦ã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´"
        ],
        "æŠ€è¡“é¸æŠ"  : [
            "â–¡ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§åŸºæœ¬çš„ãªQ/Aã‚’ç”Ÿæˆ",
            "â–¡ LLMã§è¤‡é›‘ãªæ¨è«–Q/Aã‚’è£œå®Œ",
            "â–¡ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æœ€é©åŒ–",
            "â–¡ äººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§å“è³ªä¿è¨¼"
        ],
        "è©•ä¾¡ã¨æ”¹å–„": [
            "â–¡ ã‚«ãƒãƒ¬ãƒƒã‚¸æ¸¬å®šã®å®Ÿæ–½",
            "â–¡ é‡è¤‡ã¨çŸ›ç›¾ã®æ¤œå‡º",
            "â–¡ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åé›†",
            "â–¡ ç¶™ç¶šçš„ãªæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«"
        ]
    }


def demonstrate_semantic_coverage(document_text):
    """SemanticCoverageã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("=" * 80)
    print("1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ")
    print("=" * 80)

    document_text = document_text

    # SemanticCoverageã®åˆæœŸåŒ–
    analyzer = SemanticCoverage(embedding_model="text-embedding-3-small")

    # æ–‡æ›¸ã‚’ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    print("\næ–‡æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ä¸­...")
    chunks = analyzer.create_semantic_chunks(document_text, verbose=False)

    print(f"\nâœ… {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ")
    for i, chunk in enumerate(chunks, 1):
        print(f"  ãƒãƒ£ãƒ³ã‚¯{i}: {chunk['text'][:60]}...")
        print(f"    æ–‡æ•°: {len(chunk['sentences'])}, ID: {chunk['id']}")

    return analyzer, chunks, document_text


def demonstrate_qa_generation_considerations(document_text: str):
    """QAGenerationConsiderationsã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("2. Q/Aç”Ÿæˆå‰ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ")
    print("=" * 80)

    # ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®è¡¨ç¤º
    checklist = qa_generation_checklist()

    for category, items in checklist.items():
        print(f"\nã€{category}ã€‘")
        for item in items:
            print(f"  {item}")


def demonstrate_rule_based_generation(document_text: str):
    """RuleBasedQAGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("3. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ")
    print("=" * 80)

    try:
        # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆå™¨ã®åˆæœŸåŒ–
        rule_generator = RuleBasedQAGenerator()

        # å®šç¾©æ–‡ã‹ã‚‰Q/AæŠ½å‡º
        print("\nå®šç¾©æ–‡ã‹ã‚‰Q/AæŠ½å‡ºä¸­...")
        definition_qas = rule_generator.extract_definition_qa(document_text)

        if definition_qas:
            print(f"\nâœ… {len(definition_qas)}å€‹ã®å®šç¾©Q/Aã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            for i, qa in enumerate(definition_qas, 1):
                print(f"\n  ã€å®šç¾©Q/A {i}ã€‘")
                print(f"    è³ªå•: {qa['question']}")
                print(f"    å›ç­”: {qa['answer']}")
                print(f"    ä¿¡é ¼åº¦: {qa.get('confidence', 'N/A')}")
        else:
            print("\nâš ï¸  å®šç¾©æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        return definition_qas

    except OSError as e:
        print(f"\nâš ï¸  spaCyæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("    ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰: python -m spacy download ja_core_news_lg")
        print("    ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return []


def demonstrate_template_based_generation(document_text: str):
    """TemplateBasedQAGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("4. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ")
    print("=" * 80)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ç”Ÿæˆå™¨ã®åˆæœŸåŒ–
    template_generator = TemplateBasedQAGenerator()

    # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ‰‹å‹•æŒ‡å®šï¼ˆå®Ÿéš›ã«ã¯NERã§æŠ½å‡ºï¼‰
    entities = ['AI', 'æ©Ÿæ¢°å­¦ç¿’', 'ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼', 'BERT', 'GPT']

    print(f"\nã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {', '.join(entities)}")
    print("\nã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆä¸­...")

    template_qas = []
    for entity in entities[:3]:  # æœ€åˆã®3ã¤ã§ä¾‹ç¤º
        # ç°¡æ˜“çš„ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé©ç”¨
        qa = {
            "question": f"{entity}ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "answer": f"{entity}ã«é–¢ã™ã‚‹æƒ…å ±ã¯æ–‡æ›¸å†…ã§èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚",
            "entity": entity,
            "type": "entity_based",
            "confidence": 0.75
        }
        template_qas.append(qa)

    print(f"\nâœ… {len(template_qas)}å€‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆQ/Aã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    for i, qa in enumerate(template_qas, 1):
        print(f"\n  ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆQ/A {i}ã€‘")
        print(f"    è³ªå•: {qa['question']}")
        print(f"    å›ç­”: {qa['answer']}")
        print(f"    ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {qa['entity']}")
        print(f"    ä¿¡é ¼åº¦: {qa.get('confidence', 'N/A')}")

    return template_qas


def demonstrate_llm_based_generation(document_text: str):
    """LLMBasedQAGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("5. LLMãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ")
    print("=" * 80)

    api_key = os.getenv('OPENAI_API_KEY')

    if api_key:
        try:
            print("\nLLMBasedQAGenerator ã§Q/Aç”Ÿæˆä¸­...")
            llm_generator = LLMBasedQAGenerator(model="gpt-4o-mini")
            llm_qas = llm_generator.generate_basic_qa(document_text, num_pairs=3)

            print(f"\nâœ… {len(llm_qas)}å€‹ã®LLM Q/Aã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            for i, qa in enumerate(llm_qas[:2], 1):  # æœ€åˆã®2ã¤ã‚’è¡¨ç¤º
                print(f"\n  ã€LLM Q/A {i}ã€‘")
                print(f"    è³ªå•: {qa.get('question', 'N/A')}")
                print(f"    å›ç­”: {qa.get('answer', 'N/A')[:80]}...")
                print(f"    ç¨®é¡: {qa.get('question_type', 'N/A')}")

            return llm_qas

        except Exception as e:
            print(f"\nâš ï¸  LLM Q/Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return []
    else:
        print("\nâš ï¸  OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        print("å®Ÿéš›ã®ä½¿ç”¨ä¾‹:")
        print("""
    # OpenAI APIã‚­ãƒ¼è¨­å®šå¾Œ
    llm_generator = LLMBasedQAGenerator(model="gpt-4o-mini")
    llm_qas = llm_generator.generate_basic_qa(document_text, num_pairs=3)
    """)

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        llm_qas = [
            {
                "question": "AIã®å¿œç”¨åˆ†é‡ã«ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "answer": "åŒ»ç™‚è¨ºæ–­ã‹ã‚‰è‡ªå‹•é‹è»¢ã¾ã§å¹…åºƒã„åˆ†é‡ã§å¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚",
                "question_type": "fact",
                "difficulty": "basic"
            }
        ]

        print(f"\nï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰{len(llm_qas)}å€‹ã®LLM Q/Aã‚’ç”Ÿæˆ")
        return llm_qas


def demonstrate_cot_generation(document_text: str):
    """ChainOfThoughtQAGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("6. Chain-of-Thought Q/Aç”Ÿæˆ")
    print("=" * 80)

    api_key = os.getenv('OPENAI_API_KEY')

    if api_key:
        try:
            print("\nChainOfThoughtQAGenerator ã§Q/Aç”Ÿæˆä¸­...")
            cot_generator = ChainOfThoughtQAGenerator()
            result = cot_generator.generate_with_reasoning(document_text)

            # çµæœã‹ã‚‰ qa_pairs ã‚’å–å¾—
            cot_qas = result.get('qa_pairs', []) if isinstance(result, dict) else result

            print(f"\nâœ… {len(cot_qas)}å€‹ã®CoT Q/Aã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            for i, qa in enumerate(cot_qas[:2], 1):  # æœ€åˆã®2ã¤ã‚’è¡¨ç¤º
                print(f"\n  ã€CoT Q/A {i}ã€‘")
                print(f"    è³ªå•: {qa.get('question', 'N/A')}")
                print(f"    å›ç­”: {qa.get('answer', 'N/A')[:80]}...")
                print(f"    æ¨è«–: {qa.get('reasoning', 'N/A')[:80]}...")
                print(f"    ä¿¡é ¼åº¦: {qa.get('confidence', 'N/A')}")

            return cot_qas

        except Exception as e:
            print(f"\nâš ï¸  CoT Q/Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return []
    else:
        print("\nâš ï¸  OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        print("å®Ÿéš›ã®ä½¿ç”¨ä¾‹:")
        print("""
    # OpenAI APIã‚­ãƒ¼è¨­å®šå¾Œ
    cot_generator = ChainOfThoughtQAGenerator(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))
    cot_qas = cot_generator.generate_cot_qa(document_text, num_pairs=3, include_confidence=True)
    """)

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        cot_qas = [
            {
                "question": "ãªãœãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯RNNã‚ˆã‚Šé«˜é€Ÿãªã®ã§ã™ã‹ï¼Ÿ",
                "answer": "ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã«ã‚ˆã‚Šä¸¦åˆ—å‡¦ç†ãŒå¯èƒ½ã ã‹ã‚‰ã§ã™ã€‚",
                "reasoning": "ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã‚’ä½¿ç”¨ â†’ é †æ¬¡å‡¦ç†ä¸è¦ â†’ ä¸¦åˆ—åŒ–å¯èƒ½",
                "confidence": 0.92,
                "question_type": "reason",
                "difficulty": "intermediate"
            }
        ]

        print(f"\nï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰{len(cot_qas)}å€‹ã®CoT Q/Aã‚’ç”Ÿæˆ")

        return cot_qas


def demonstrate_hybrid_generation(document_text: str, rule_qas: List[Dict], template_qas: List[Dict]):
    """HybridQAGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("7. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Q/Aç”Ÿæˆï¼ˆçµ±åˆï¼‰")
    print("=" * 80)

    # å…¨Q/Aã‚’çµ±åˆ
    all_qas = []
    all_qas.extend(rule_qas)
    all_qas.extend(template_qas)

    print(f"\nçµ±åˆçµæœ:")
    print(f"  - ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹: {len(rule_qas)}å€‹")
    print(f"  - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹: {len(template_qas)}å€‹")
    print(f"  - åˆè¨ˆ: {len(all_qas)}å€‹")

    # ç°¡æ˜“çš„ãªé‡è¤‡é™¤å»
    unique_questions = {}
    for qa in all_qas:
        q = qa['question']
        if q not in unique_questions:
            unique_questions[q] = qa

    unique_qas = list(unique_questions.values())

    print(f"\né‡è¤‡é™¤å»å¾Œ: {len(unique_qas)}å€‹")

    # çµ±åˆã•ã‚ŒãŸQ/Aãƒšã‚¢ã®è¡¨ç¤º
    print(f"\nã€çµ±åˆQ/Aãƒšã‚¢ï¼ˆæœ€åˆã®3å€‹ï¼‰ã€‘")
    for i, qa in enumerate(unique_qas[:3], 1):
        print(f"\n  ã€çµ±åˆQ/A {i}ã€‘")
        print(f"    è³ªå•: {qa.get('question', 'N/A')}")
        print(f"    å›ç­”: {qa.get('answer', 'N/A')[:80]}{'...' if len(qa.get('answer', '')) > 80 else ''}")
        print(f"    ã‚¿ã‚¤ãƒ—: {qa.get('type', 'N/A')}")
        print(f"    ä¿¡é ¼åº¦: {qa.get('confidence', 'N/A')}")

    return unique_qas


def demonstrate_advanced_techniques(document_text: str):
    """AdvancedQAGenerationTechniquesã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("8. é«˜åº¦ãªQ/Aç”ŸæˆæŠ€è¡“")
    print("=" * 80)

    api_key = os.getenv('OPENAI_API_KEY')

    if api_key:
        try:
            print("\nAdvancedQAGenerationTechniques ã§Q/Aç”Ÿæˆä¸­...")
            advanced_gen = AdvancedQAGenerationTechniques()

            # æ•µå¯¾çš„Q/Aç”Ÿæˆï¼ˆæ—¢å­˜ã®Q/Aãƒšã‚¢ãŒå¿…è¦ãªãŸã‚ã€ç°¡æ˜“çš„ãªã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆï¼‰
            print("\næ•µå¯¾çš„Q/Aç”Ÿæˆä¸­...")
            sample_qa = [{"question": "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ", "answer": "æ¤œç´¢æ‹¡å¼µç”Ÿæˆã§ã™"}]
            adversarial_qas = advanced_gen.generate_adversarial_qa(document_text, existing_qa=sample_qa)

            print(f"\nâœ… {len(adversarial_qas)}å€‹ã®é«˜åº¦ãªQ/Aã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            for i, qa in enumerate(adversarial_qas[:2], 1):
                print(f"\n  ã€é«˜åº¦ãªQ/A {i}ã€‘")
                print(f"    è³ªå•: {qa.get('question', 'N/A')}")
                print(f"    å›ç­”: {qa.get('answer', 'N/A')[:80]}...")
                print(f"    ã‚¿ã‚¤ãƒ—: {qa.get('type', 'N/A')}")

            return adversarial_qas

        except Exception as e:
            print(f"\nâš ï¸  é«˜åº¦ãªQ/Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return []
    else:
        print("\nâš ï¸  OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        print("å®Ÿéš›ã®ä½¿ç”¨ä¾‹:")
        print("""
    # OpenAI APIã‚­ãƒ¼è¨­å®šå¾Œ
    advanced_gen = AdvancedQAGenerationTechniques(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))

    # æ•µå¯¾çš„Q/Aç”Ÿæˆ
    adversarial_qas = advanced_gen.generate_adversarial_qa(document_text, num_pairs=3)

    # ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–Q/Aç”Ÿæˆ
    multihop_qas = advanced_gen.generate_multihop_qa(document_text, chunks, num_pairs=2)

    # åäº‹å®Ÿçš„Q/Aç”Ÿæˆ
    counterfactual_qas = advanced_gen.generate_counterfactual_qa(document_text, num_pairs=2)
    """)

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        advanced_qas = [
            {
                "question": "ã‚‚ã—ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒé–‹ç™ºã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚‰ã€NLPã¯ã©ã†ãªã£ã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                "answer": "RNNãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸»æµã®ã¾ã¾ã€å‡¦ç†é€Ÿåº¦ã¨ç²¾åº¦ã®ä¸¡ç«‹ãŒå›°é›£ã ã£ãŸã§ã—ã‚‡ã†ã€‚",
                "type": "counterfactual",
                "difficulty": "advanced"
            }
        ]

        print(f"\nï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰{len(advanced_qas)}å€‹ã®é«˜åº¦ãªQ/Aã‚’ç”Ÿæˆ")

        return advanced_qas


def demonstrate_coverage_optimization(analyzer, chunks, document_text: str, all_qas: List[Dict]):
    """QAGenerationOptimizerã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("\n\n" + "=" * 80)
    print("9. ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€é©åŒ–")
    print("=" * 80)

    api_key = os.getenv('OPENAI_API_KEY')

    if api_key and analyzer.has_api_key:
        try:
            print("\nã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã‚’å®Ÿè¡Œä¸­...")

            # æ–‡æ›¸ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
            doc_embeddings = analyzer.generate_embeddings(chunks)

            # Q/Aãƒšã‚¢ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
            qa_texts = [qa.get('question', '') + ' ' + qa.get('answer', '') for qa in all_qas if qa.get('question') and qa.get('answer')]

            if not qa_texts:
                print("\nâš ï¸  æœ‰åŠ¹ãªQ/Aãƒšã‚¢ãŒã‚ã‚Šã¾ã›ã‚“")
                return

            # å„Q/Aã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
            qa_embeddings = []
            for qa_text in qa_texts:
                emb = analyzer.generate_embedding(qa_text)
                qa_embeddings.append(emb)

            # ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’è¨ˆç®—ï¼ˆé–¾å€¤0.7ä»¥ä¸Šã§ã€Œã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã€ã¨åˆ¤å®šï¼‰
            threshold = 0.7
            covered_chunks = set()

            for qa_emb in qa_embeddings:
                for i, doc_emb in enumerate(doc_embeddings):
                    similarity = analyzer.cosine_similarity(doc_emb, qa_emb)
                    if similarity >= threshold:
                        covered_chunks.add(i)

            coverage_rate = len(covered_chunks) / len(chunks) if len(chunks) > 0 else 0

            print(f"\nâœ… ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æå®Œäº†")
            print(f"  ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")
            print(f"  ã‚«ãƒãƒ¼ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯: {len(covered_chunks)}")
            print(f"  ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡: {coverage_rate:.1%}")
            print(f"  ç·Q/Aæ•°: {len(all_qas)}")

            if coverage_rate < 0.8:
                uncovered_count = len(chunks) - len(covered_chunks)
                print(f"\nğŸ’¡ æ¨å¥¨: ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„ãƒãƒ£ãƒ³ã‚¯ãŒ{uncovered_count}å€‹ã‚ã‚Šã¾ã™")
                print(f"   è¿½åŠ ã§{uncovered_count * 2}å€‹ç¨‹åº¦ã®Q/Aãƒšã‚¢ç”Ÿæˆã‚’æ¨å¥¨ã—ã¾ã™")

        except Exception as e:
            print(f"\nâš ï¸  ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            print("    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¡¨ç¤º
            print(f"\nï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€é©åŒ–çµæœ:")
            print(f"  åˆæœŸã‚«ãƒãƒ¬ãƒƒã‚¸: 65.0%")
            print(f"  æœ€çµ‚ã‚«ãƒãƒ¬ãƒƒã‚¸: 95.0%")
            print(f"  æ”¹å–„åº¦: +30.0%")
            print(f"  æ–°è¦ç”ŸæˆQ/Aæ•°: 8å€‹")
            print(f"  ç·Q/Aæ•°: {len(all_qas) + 8}å€‹")
    else:
        print("\nâš ï¸  OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼‰")
        print("\nå®Ÿéš›ã®ä½¿ç”¨ä¾‹:")
        print("""
    # OpenAI APIã‚­ãƒ¼è¨­å®šå¾Œ
    optimizer = QAGenerationOptimizer(analyzer=analyzer, generator=hybrid_gen)

    optimized_result = optimizer.optimize_coverage(
        document_text=document_text,
        existing_qa_pairs=all_qas,
        target_coverage=0.95,
        max_iterations=5
    )

    print(f"åˆæœŸã‚«ãƒãƒ¬ãƒƒã‚¸: {optimized_result['initial_coverage']:.2%}")
    print(f"æœ€çµ‚ã‚«ãƒãƒ¬ãƒƒã‚¸: {optimized_result['coverage_rate']:.2%}")
    print(f"æ”¹å–„åº¦: +{optimized_result['improvement']:.2%}")
    """)

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
        print(f"\nï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€é©åŒ–çµæœ:")
        print(f"  åˆæœŸã‚«ãƒãƒ¬ãƒƒã‚¸: 65.0%")
        print(f"  æœ€çµ‚ã‚«ãƒãƒ¬ãƒƒã‚¸: 95.0%")
        print(f"  æ”¹å–„åº¦: +30.0%")
        print(f"  æ–°è¦ç”ŸæˆQ/Aæ•°: 8å€‹")
        print(f"  ç·Q/Aæ•°: {len(all_qas) + 8}å€‹")


def export_results(all_qas: List[Dict], output_file: str = "a03_qa_results.json"):
    """ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

    print("\n\n" + "=" * 80)
    print("10. çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("=" * 80)

    export_data = {
        "total_qa_pairs": len(all_qas),
        "generation_methods": {
            "rule_based": len([qa for qa in all_qas if qa.get('type') == 'definition' or qa.get('type') == 'terminology']),
            "template_based": len([qa for qa in all_qas if qa.get('type') == 'entity_based']),
            "llm_based": len([qa for qa in all_qas if qa.get('question_type') in ['fact', 'reason']]),
        },
        "qa_pairs": all_qas
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… Q/Aç”Ÿæˆçµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print(f"ç·Q/Aæ•°: {export_data['total_qa_pairs']}")
    print(f"ç”Ÿæˆæ‰‹æ³•åˆ¥:")
    for method, count in export_data['generation_methods'].items():
        print(f"  - {method}: {count}å€‹")

def print_doc():
    print("""
        1. document_text (str)
          - å‹: str
          - å†…å®¹: RAGã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆ233æ–‡å­—ã€5æ–‡ï¼‰
          - å½¹å‰²: å…¨ã¦ã®Q/Aç”Ÿæˆå‡¦ç†ã®å…¥åŠ›ã¨ãªã‚‹å…ƒãƒ†ã‚­ã‚¹ãƒˆ
            """)
    print("document_text =:", document_text)

    print("""
        2. chunks (List[Dict])

          - å‹: List[Dict[str, Any]]
          - è¦ç´ æ•°: 1å€‹ï¼ˆã“ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã¯å…¨æ–‡ãŒ1ãƒãƒ£ãƒ³ã‚¯ã«åã¾ã‚‹ï¼‰
          - å„ãƒãƒ£ãƒ³ã‚¯ã®æ§‹é€ :
          {
              "id": str,                    # "chunk_0"
              "text": str,                  # ãƒãƒ£ãƒ³ã‚¯å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆ
              "sentences": List[str],       # å€‹åˆ¥ã®æ–‡ã®ãƒªã‚¹ãƒˆ
              "start_sentence_idx": int,    # é–‹å§‹æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (0)
              "end_sentence_idx": int       # çµ‚äº†æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (4)
          }
          - å½¹å‰²: æ–‡æ›¸ã‚’æ„å‘³çš„ã«åˆ†å‰²ã—ãŸå˜ä½ã€‚ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã§ä½¿ç”¨

        3. analyzer (SemanticCoverage)

          - å‹: SemanticCoverage (helper_rag_qa.SemanticCoverage)
          - ä¸»è¦å±æ€§:
            - embedding_model: "text-embedding-3-small"
            - has_api_key: True
            - client: OpenAI()
          - ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰:
            - create_semantic_chunks(text) â†’ List[Dict]
            - generate_embeddings(chunks) â†’ List[np.ndarray]
            - generate_embedding(text) â†’ np.ndarray
            - cosine_similarity(vec1, vec2) â†’ float
          - å½¹å‰²: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã®ä¸­æ ¸ã€‚ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã€åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã€é¡ä¼¼åº¦è¨ˆç®—ã‚’å®Ÿè¡Œ

          ã“ã®3ã¤ã®å¤‰æ•°ãŒé€£æºã—ã¦ã€æ–‡æ›¸ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
            """)

    print(""" -----------------------------------------------------------
    
    ã€1. create_semantic_chunks(document: str, verbose: bool = True) â†’ List[Dict]ã€‘

      èª¬æ˜: æ–‡æ›¸ã‚’æ„å‘³çš„ã«åŒºåˆ‡ã‚‰ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²

      å‡¦ç†æ‰‹é †:
        1. æ–‡å˜ä½ã§åˆ†å‰²ï¼ˆ_split_into_sentences()ï¼‰
           - æ—¥æœ¬èª: ã€‚ï¼.!? ã§åˆ†å‰²
           - è‹±èª: . ! ? ã§åˆ†å‰²

        2. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—ã—ãªãŒã‚‰ãƒãƒ£ãƒ³ã‚¯æ§‹ç¯‰
           - max_tokens = 200 ãƒˆãƒ¼ã‚¯ãƒ³/ãƒãƒ£ãƒ³ã‚¯
           - æ–‡ã®é€”ä¸­ã§ã¯åˆ†å‰²ã—ãªã„ï¼ˆæ„å‘³ã®æ–­çµ¶ã‚’é˜²ãï¼‰

        3. ãƒˆãƒ”ãƒƒã‚¯ã®é€£ç¶šæ€§ã‚’è€ƒæ…®ã—ãŸèª¿æ•´
           - _adjust_chunks_for_topic_continuity()ã§æœ€é©åŒ–

      æˆ»ã‚Šå€¤: List[Dict]
        å„ãƒãƒ£ãƒ³ã‚¯: {
          "id": "chunk_0",
          "text": "ãƒãƒ£ãƒ³ã‚¯å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆ",
          "sentences": ["æ–‡1", "æ–‡2", ...],
          "start_sentence_idx": 0,
          "end_sentence_idx": 2
        }

    ã€2. generate_embeddings(chunks: List[Dict]) â†’ List[np.ndarray]ã€‘

      èª¬æ˜: è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’ãƒãƒƒãƒç”Ÿæˆ

      å‡¦ç†æ‰‹é †:
        1. å„ãƒãƒ£ãƒ³ã‚¯ã®textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
        2. OpenAI Embeddings APIã«ä¸€æ‹¬é€ä¿¡
           client.embeddings.create(
             input=[chunk["text"] for chunk in chunks],
             model=self.embedding_model
           )
        3. è¿”å´ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’L2æ­£è¦åŒ–

      æˆ»ã‚Šå€¤: List[np.ndarray]
        å„ãƒ™ã‚¯ãƒˆãƒ«: 1536æ¬¡å…ƒã®numpyé…åˆ—

    ã€3. generate_embedding(text: str) â†’ np.ndarrayã€‘

      èª¬æ˜: å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ

      å‡¦ç†æ‰‹é †:
        1. ãƒ†ã‚­ã‚¹ãƒˆã‚’OpenAI APIã«é€ä¿¡
        2. åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
        3. L2æ­£è¦åŒ–ã—ã¦è¿”å´

      æˆ»ã‚Šå€¤: np.ndarray (1536æ¬¡å…ƒ)

      ç”¨é€”: Q/Aãƒšã‚¢ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ

    ã€4. cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) â†’ floatã€‘

      èª¬æ˜: 2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—

      è¨ˆç®—å¼:
        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

      æˆ»ã‚Šå€¤: float (0.0ã€œ1.0)
        - 1.0: å®Œå…¨ã«ä¸€è‡´
        - 0.7ä»¥ä¸Š: é«˜ã„é¡ä¼¼æ€§ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸åˆ¤å®šã®é–¾å€¤ï¼‰
        - 0.0: å…¨ãé–¢é€£æ€§ãªã—

      ç”¨é€”: Q/Aãƒšã‚¢ã¨æ–‡æ›¸ãƒãƒ£ãƒ³ã‚¯ã®é–¢é€£æ€§è©•ä¾¡
        """)

def main():
    # 1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
    import pprint

    # ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸
    document_text = """
    RAGã‚·ã‚¹ãƒ†ãƒ ã¯ã€Retrieval-Augmented Generationã®ç•¥ã§ã€æ¤œç´¢æ‹¡å¼µç”Ÿæˆã¨å‘¼ã°ã‚Œã¾ã™ã€‚
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨æƒ…å ±æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸæŠ€è¡“ã§ã™ã€‚
    RAGã®ä¸»ãªåˆ©ç‚¹ã¯ã€å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’å–å¾—ã—ã€ã‚ˆã‚Šæ­£ç¢ºãªå›ç­”ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã§ã™ã€‚
    Qdrantã¯ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€é«˜é€Ÿãªé¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
    OpenAIã®text-embedding-3-smallãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã«å¤‰æ›ã—ã¾ã™ã€‚
    """

    analyzer, chunks, document_text = demonstrate_semantic_coverage(document_text)

    print("document_text =:", document_text)

    print("\nå…¨ã¦ã®å±æ€§: -------------------------------------")
    for attr in dir(analyzer):
        if not attr.startswith('_'):
            value = getattr(analyzer, attr)
            if not callable(value):
                print(f"  - {attr}: {value}")

    print("\nå…¨ã¦ã®ãƒ¡ã‚½ãƒƒãƒ‰:------------------------------------")
    for attr in dir(analyzer):
        if not attr.startswith('_') and callable(getattr(analyzer, attr)):
            print(f"  - {attr}()")



def main2():
    import pprint

    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""

    print("\n" + "=" * 80)
    print("ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æã¨Q/Aç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 80)

    # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    api_key = os.getenv('OPENAI_API_KEY')
    print(f"\nğŸ“‹ ç’°å¢ƒãƒã‚§ãƒƒã‚¯:")
    print(f"  OpenAI APIã‚­ãƒ¼: {'âœ… è¨­å®šæ¸ˆã¿' if api_key else 'âŒ æœªè¨­å®š'}")
    if api_key:
        print(f"  å‹•ä½œãƒ¢ãƒ¼ãƒ‰: ãƒ•ãƒ«æ©Ÿèƒ½ï¼ˆå…¨ã¦ã®LLM APIã‚’ä½¿ç”¨ï¼‰")
    else:
        print(f"  å‹•ä½œãƒ¢ãƒ¼ãƒ‰: å®Œå…¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print()

    # 1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
    import pprint

    # ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸
    document_text = """
    RAGã‚·ã‚¹ãƒ†ãƒ ã¯ã€Retrieval-Augmented Generationã®ç•¥ã§ã€æ¤œç´¢æ‹¡å¼µç”Ÿæˆã¨å‘¼ã°ã‚Œã¾ã™ã€‚
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨æƒ…å ±æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸæŠ€è¡“ã§ã™ã€‚
    RAGã®ä¸»ãªåˆ©ç‚¹ã¯ã€å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’å–å¾—ã—ã€ã‚ˆã‚Šæ­£ç¢ºãªå›ç­”ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã§ã™ã€‚
    Qdrantã¯ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€é«˜é€Ÿãªé¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
    OpenAIã®text-embedding-3-smallãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã«å¤‰æ›ã—ã¾ã™ã€‚
    """
    analyzer, chunks, document_text = demonstrate_semantic_coverage(document_text)

    pprint.pprint(analyzer)

    # 2. Q/Aç”Ÿæˆå‰ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
    demonstrate_qa_generation_considerations(document_text)

    # 3. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ
    rule_qas = demonstrate_rule_based_generation(document_text)

    # 4. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ
    template_qas = demonstrate_template_based_generation(document_text)

    # 5. LLMãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    llm_qas = demonstrate_llm_based_generation(document_text)

    # 6. Chain-of-Thought Q/Aç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    cot_qas = demonstrate_cot_generation(document_text)

    # 7. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Q/Aç”Ÿæˆ
    all_qas = demonstrate_hybrid_generation(document_text, rule_qas, template_qas)

    # 8. é«˜åº¦ãªQ/Aç”ŸæˆæŠ€è¡“ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    advanced_qas = demonstrate_advanced_techniques(document_text)

    # 9. ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€é©åŒ–ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    demonstrate_coverage_optimization(analyzer, chunks, document_text, all_qas)

    # 10. çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    export_results(all_qas)

    # ã¾ã¨ã‚
    print("\n\n" + "=" * 80)
    print("ã¾ã¨ã‚")
    print("=" * 80)
    print("\næœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´:")
    print("  âœ… SemanticCoverage - æ–‡æ›¸ã®æ„å‘³çš„ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã¨åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ")
    print("  âœ… RuleBasedQAGenerator - ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹ç¢ºå®ŸãªQ/Aç”Ÿæˆ")
    print("  âœ… TemplateBasedQAGenerator - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹Q/Aç”Ÿæˆ")
    print("  âœ… LLMBasedQAGenerator - GPTã«ã‚ˆã‚‹å¤šæ§˜ãªQ/Aç”Ÿæˆï¼ˆè¦APIã‚­ãƒ¼ï¼‰")
    print("  âœ… ChainOfThoughtQAGenerator - æ¨è«–éç¨‹ä»˜ãé«˜å“è³ªQ/Aï¼ˆè¦APIã‚­ãƒ¼ï¼‰")
    print("  âœ… HybridQAGenerator - è¤‡æ•°æ‰‹æ³•ã®çµ±åˆã¨å“è³ªæ¤œè¨¼")
    print("  âœ… AdvancedQAGenerationTechniques - æ•µå¯¾çš„ãƒ»ãƒãƒ«ãƒãƒ›ãƒƒãƒ—ãƒ»åäº‹å®Ÿçš„Q/Aï¼ˆè¦APIã‚­ãƒ¼ï¼‰")
    print("  âœ… QAGenerationOptimizer - ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€é©åŒ–ã¨ã‚³ã‚¹ãƒˆç®¡ç†ï¼ˆè¦APIã‚­ãƒ¼ï¼‰")
    print("=" * 80)


if __name__ == "__main__":
    main()

