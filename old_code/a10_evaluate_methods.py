#!/usr/bin/env python3
"""
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæ‰‹æ³•ã®æ¯”è¼ƒè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç•°ãªã‚‹ç‰¹æ€§ã®ãƒ†ã‚­ã‚¹ãƒˆã§å„æ‰‹æ³•ã®æ€§èƒ½ã‚’æ¤œè¨¼
python a10_evaluate_methods.py
"""

from regex_mecab import KeywordExtractor
from typing import Dict, List, Tuple
import re


def create_test_cases() -> Dict[str, str]:
    """è©•ä¾¡ç”¨ã®å¤šæ§˜ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½œæˆ"""

    test_cases = {
        # ã‚±ãƒ¼ã‚¹1: è¤‡åˆåè©ãŒå¤šã„æŠ€è¡“æ–‡æ›¸
        "è¤‡åˆåè©å„ªä½": """
            è‡ªç„¶è¨€èªå‡¦ç†æŠ€è¡“ã€æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€
            ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€
            ãƒªã‚«ãƒ¬ãƒ³ãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€æ•µå¯¾çš„ç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€
            ãƒ™ã‚¤ã‚ºæœ€é©åŒ–æ‰‹æ³•ã€å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€è»¢ç§»å­¦ç¿’æŠ€è¡“
        """,

        # ã‚±ãƒ¼ã‚¹2: å˜ä¸€åè©ãŒå¤šã„æ–‡æ›¸
        "å˜ä¸€åè©å„ªä½": """
            ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ”¹å–„ã™ã‚‹ã€‚
            ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã€‚ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ã€‚
            ã‚·ã‚¹ãƒ†ãƒ ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã€‚çµæœã‚’è©•ä¾¡ã™ã‚‹ã€‚
            ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã€‚
        """,

        # ã‚±ãƒ¼ã‚¹3: ã‚«ã‚¿ã‚«ãƒŠèªä¸­å¿ƒ
        "ã‚«ã‚¿ã‚«ãƒŠèªä¸­å¿ƒ": """
            ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã€
            ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã€ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€
            ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚¢ã‚¸ãƒ£ã‚¤ãƒ«ãƒ¡ã‚½ãƒ‰ãƒ­ã‚¸ãƒ¼ã€
            ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        """,

        # ã‚±ãƒ¼ã‚¹4: è‹±èªç•¥èªä¸­å¿ƒ
        "è‹±èªç•¥èªä¸­å¿ƒ": """
            AIã€MLã€DLã€NLPã€CVã€GANã€CNNã€RNNã€LSTMã€BERTã€
            GPTã€APIã€SDKã€IDEã€CIã€CDã€DevOpsã€SaaSã€PaaSã€IaaSã€
            IoTã€ARã€VRã€MRã€XRã€5Gã€WiFiã€HTTPã€RESTã€JSON
        """,

        # ã‚±ãƒ¼ã‚¹5: æ—¥æœ¬èªä¸€èˆ¬æ–‡æ›¸
        "æ—¥æœ¬èªä¸€èˆ¬æ–‡æ›¸": """
            æ—¥æœ¬ã®ä¼çµ±æ–‡åŒ–ã¯ã€é•·ã„æ­´å²ã®ä¸­ã§åŸ¹ã‚ã‚Œã¦ãã¾ã—ãŸã€‚
            èŒ¶é“ã€è¯é“ã€æ›¸é“ãªã©ã®èŠ¸é“ã¯ã€ç²¾ç¥æ€§ã‚’é‡è¦–ã—ã¾ã™ã€‚
            å’Œé£Ÿã¯ã€å­£ç¯€ã®é£Ÿæã‚’å¤§åˆ‡ã«ã—ã€ç¾ã—ã„ç››ã‚Šä»˜ã‘ãŒç‰¹å¾´ã§ã™ã€‚
            ç€ç‰©ã¯ã€æ—¥æœ¬ã®ç¾æ„è­˜ã‚’è¡¨ç¾ã™ã‚‹ä¼çµ±çš„ãªè¡£è£…ã§ã™ã€‚
            ç¥­ã‚Šã‚„å¹´ä¸­è¡Œäº‹ã¯ã€åœ°åŸŸç¤¾ä¼šã®çµ†ã‚’æ·±ã‚ã‚‹é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚
        """,

        # ã‚±ãƒ¼ã‚¹6: æ··åœ¨å‹ï¼ˆå®Ÿéš›ã®ãƒ–ãƒ­ã‚°è¨˜äº‹é¢¨ï¼‰
        "æ··åœ¨å‹ãƒ–ãƒ­ã‚°": """
            æœ€è¿‘ã®AIãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚ChatGPTã®ç™»å ´ã«ã‚ˆã‚Šã€
            è‡ªç„¶è¨€èªå‡¦ç†ã®åˆ†é‡ãŒå¤§ããå¤‰åŒ–ã—ã¾ã—ãŸã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€
            å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã¨ã¯ç•°ãªã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ã„ã†
            æ–°ã—ã„ã‚¹ã‚­ãƒ«ãŒé‡è¦ã«ãªã£ã¦ãã¦ã„ã¾ã™ã€‚APIã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€
            èª°ã§ã‚‚ç°¡å˜ã«AIã‚’æ´»ç”¨ã§ãã‚‹æ™‚ä»£ã«ãªã‚Šã¾ã—ãŸã€‚
        """,

        # ã‚±ãƒ¼ã‚¹7: çŸ­æ–‡ã®ç¾…åˆ—
        "çŸ­æ–‡ç¾…åˆ—": """
            AIé©å‘½ã€‚ãƒ‡ãƒ¼ã‚¿åˆ†æã€‚æ©Ÿæ¢°å­¦ç¿’ã€‚æ·±å±¤å­¦ç¿’ã€‚
            ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ã€‚IoTã€‚5Gé€šä¿¡ã€‚
            é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã€‚ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã€‚
            ãƒ¡ã‚¿ãƒãƒ¼ã‚¹ã€‚NFTã€‚Web3ã€‚DXæ¨é€²ã€‚
        """,

        # ã‚±ãƒ¼ã‚¹8: èª¬æ˜çš„ãªé•·æ–‡
        "èª¬æ˜çš„é•·æ–‡": """
            äººå·¥çŸ¥èƒ½ã¨ã¯ã€äººé–“ã®çŸ¥çš„èƒ½åŠ›ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ä¸Šã§å®Ÿç¾ã™ã‚‹æŠ€è¡“ã§ã‚ã‚Šã€
            ãã®å¿œç”¨ç¯„å›²ã¯éå¸¸ã«åºƒãã€ç”»åƒèªè­˜ã‹ã‚‰è‡ªç„¶è¨€èªå‡¦ç†ã€éŸ³å£°èªè­˜ã€
            ã‚²ãƒ¼ãƒ ãƒ—ãƒ¬ã‚¤ãƒ³ã‚°ã€è‡ªå‹•é‹è»¢ãªã©å¤šå²ã«ã‚ãŸã‚Šã¾ã™ã€‚ç‰¹ã«è¿‘å¹´ã§ã¯ã€
            ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã‚‹å¤šå±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸ
            æ‰‹æ³•ãŒå¤§ããªæˆæœã‚’ä¸Šã’ã¦ãŠã‚Šã€ã“ã‚Œã¾ã§å›°é›£ã¨ã•ã‚Œã¦ã„ãŸå•é¡Œã‚’
            æ¬¡ã€…ã¨è§£æ±ºã—ã¦ã„ã¾ã™ã€‚
        """,

        # ã‚±ãƒ¼ã‚¹9: å°‚é–€ç”¨èªãªã—æ—¥å¸¸ä¼šè©±
        "æ—¥å¸¸ä¼šè©±": """
            ä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã‹ã£ãŸã®ã§ã€å…¬åœ’ã«æ•£æ­©ã«è¡Œãã¾ã—ãŸã€‚
            æ¡œã®èŠ±ãŒæº€é–‹ã§ã€ã¨ã¦ã‚‚ç¶ºéº—ã§ã—ãŸã€‚å®¶æ—é€£ã‚Œã‚„å‹é”åŒå£«ã§
            ãŠèŠ±è¦‹ã‚’æ¥½ã—ã‚“ã§ã„ã‚‹äººãŒãŸãã•ã‚“ã„ã¾ã—ãŸã€‚
            æ˜¥ã®é™½æ°—ã«èª˜ã‚ã‚Œã¦ã€ã‚¢ã‚¤ã‚¹ã‚¯ãƒªãƒ¼ãƒ ã‚’é£Ÿã¹ãªãŒã‚‰
            ãƒ™ãƒ³ãƒã§ã®ã‚“ã³ã‚Šéã”ã—ã¾ã—ãŸã€‚
        """,

        # ã‚±ãƒ¼ã‚¹10: æ•°å­—ãƒ»è¨˜å·æ··åœ¨
        "æ•°å­—è¨˜å·æ··åœ¨": """
            2024å¹´ã®AIå¸‚å ´è¦æ¨¡ã¯ç´„1500å„„ãƒ‰ãƒ«ã«é”ã—ã€å‰å¹´æ¯”25%ã®æˆé•·ç‡ã€‚
            GPT-4ã¯1750å„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¡ã€GPT-3.5ã®10å€ã®æ€§èƒ½ã€‚
            5Gé€šä¿¡ã¯æœ€å¤§20Gbpsã®é€šä¿¡é€Ÿåº¦ã‚’å®Ÿç¾ã—ã€4Gã®100å€é«˜é€Ÿã€‚
            é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯2^100ã®è¨ˆç®—ã‚’åŒæ™‚ã«å‡¦ç†å¯èƒ½ã€‚
        """
    }

    return test_cases


def evaluate_extraction_quality(keywords: List[str], text: str, case_type: str) -> Dict[str, float]:
    """æŠ½å‡ºå“è³ªã‚’è©•ä¾¡ã™ã‚‹æŒ‡æ¨™ã‚’è¨ˆç®—"""

    metrics = {}

    # 1. ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡ï¼ˆæŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãƒ†ã‚­ã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹å‰²åˆï¼‰
    coverage = sum(1 for kw in keywords if kw in text) / len(keywords) if keywords else 0
    metrics['ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡'] = coverage

    # 2. å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–‡å­—æ•°ã®ã°ã‚‰ã¤ãï¼‰
    if keywords:
        lengths = [len(kw) for kw in keywords]
        avg_len = sum(lengths) / len(lengths)
        variance = sum((l - avg_len) ** 2 for l in lengths) / len(lengths)
        metrics['å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢'] = min(variance / 10, 1.0)  # æ­£è¦åŒ–
    else:
        metrics['å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢'] = 0

    # 3. å°‚é–€æ€§ã‚¹ã‚³ã‚¢ï¼ˆã‚«ã‚¿ã‚«ãƒŠãƒ»è‹±èªãƒ»æ¼¢å­—è¤‡åˆèªã®å‰²åˆï¼‰
    if keywords:
        technical_pattern = r'^([ã‚¡-ãƒ´ãƒ¼]{3,}|[A-Z]{2,}|[ä¸€-é¾¥]{4,})$'
        technical_ratio = sum(1 for kw in keywords if re.match(technical_pattern, kw)) / len(keywords)
        metrics['å°‚é–€æ€§ã‚¹ã‚³ã‚¢'] = technical_ratio
    else:
        metrics['å°‚é–€æ€§ã‚¹ã‚³ã‚¢'] = 0

    # 4. ã‚±ãƒ¼ã‚¹åˆ¥é©åˆåº¦
    case_scores = {
        "è¤‡åˆåè©å„ªä½": lambda kws: sum(1 for kw in kws if len(kw) >= 6) / len(kws) if kws else 0,
        "å˜ä¸€åè©å„ªä½": lambda kws: sum(1 for kw in kws if 2 <= len(kw) <= 4) / len(kws) if kws else 0,
        "ã‚«ã‚¿ã‚«ãƒŠèªä¸­å¿ƒ": lambda kws: sum(1 for kw in kws if re.match(r'^[ã‚¡-ãƒ´ãƒ¼]+$', kw)) / len(kws) if kws else 0,
        "è‹±èªç•¥èªä¸­å¿ƒ": lambda kws: sum(1 for kw in kws if re.match(r'^[A-Z]+$', kw)) / len(kws) if kws else 0,
        "æ—¥æœ¬èªä¸€èˆ¬æ–‡æ›¸": lambda kws: sum(1 for kw in kws if re.match(r'^[ã-ã‚“ä¸€-é¾¥]+$', kw)) / len(kws) if kws else 0,
    }

    if case_type in case_scores:
        metrics['ã‚±ãƒ¼ã‚¹é©åˆåº¦'] = case_scores[case_type](keywords)
    else:
        metrics['ã‚±ãƒ¼ã‚¹é©åˆåº¦'] = coverage  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡

    # 5. ç·åˆã‚¹ã‚³ã‚¢
    metrics['ç·åˆã‚¹ã‚³ã‚¢'] = (
        metrics['ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡'] * 0.3 +
        metrics['å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢'] * 0.1 +
        metrics['å°‚é–€æ€§ã‚¹ã‚³ã‚¢'] * 0.3 +
        metrics['ã‚±ãƒ¼ã‚¹é©åˆåº¦'] * 0.3
    )

    return metrics


def run_comprehensive_evaluation():
    """åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚’å®Ÿè¡Œ"""

    print("=" * 100)
    print("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæ‰‹æ³•ã®åŒ…æ‹¬çš„è©•ä¾¡")
    print("=" * 100)

    test_cases = create_test_cases()
    extractor = KeywordExtractor(prefer_mecab=True)

    # çµæœã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
    all_results = {}
    method_scores = {"MeCabè¤‡åˆåè©": [], "æ­£è¦è¡¨ç¾": [], "çµ±åˆç‰ˆ": []}

    for case_name, text in test_cases.items():
        print(f"\nã€ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {case_name}ã€‘")
        print("-" * 80)
        print(f"ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå†’é ­50æ–‡å­—ï¼‰: {text[:50].strip()}...")
        print()

        # å„æ‰‹æ³•ã§æŠ½å‡º
        results = extractor.extract_with_details(text, top_n=5)

        case_results = {}
        for method, keywords_scores in results.items():
            keywords = [kw for kw, _ in keywords_scores]

            # å“è³ªè©•ä¾¡
            metrics = evaluate_extraction_quality(keywords, text, case_name)
            case_results[method] = {
                'keywords': keywords[:5],  # ä¸Šä½5ä»¶
                'metrics': metrics
            }

            # ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²
            if method in method_scores:
                method_scores[method].append(metrics['ç·åˆã‚¹ã‚³ã‚¢'])

            print(f"  {method}:")
            print(f"    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords[:5]) if keywords else 'ãªã—'}")
            print(f"    ç·åˆã‚¹ã‚³ã‚¢: {metrics['ç·åˆã‚¹ã‚³ã‚¢']:.3f}")

        all_results[case_name] = case_results

        # æœ€è‰¯ã®æ‰‹æ³•ã‚’ç‰¹å®š
        best_method = max(case_results.items(),
                         key=lambda x: x[1]['metrics']['ç·åˆã‚¹ã‚³ã‚¢'])
        print(f"\n  ğŸ† æœ€è‰¯æ‰‹æ³•: {best_method[0]} (ã‚¹ã‚³ã‚¢: {best_method[1]['metrics']['ç·åˆã‚¹ã‚³ã‚¢']:.3f})")

    # ç·åˆåˆ†æ
    print("\n" + "=" * 100)
    print("ç·åˆåˆ†æçµæœ")
    print("=" * 100)

    # å„æ‰‹æ³•ã®å¹³å‡ã‚¹ã‚³ã‚¢
    print("\nã€å¹³å‡ç·åˆã‚¹ã‚³ã‚¢ã€‘")
    avg_scores = {}
    for method, scores in method_scores.items():
        if scores:
            avg = sum(scores) / len(scores)
            avg_scores[method] = avg
            print(f"  {method}: {avg:.3f}")

    # å„æ‰‹æ³•ãŒæœ€è‰¯ã ã£ãŸã‚±ãƒ¼ã‚¹æ•°
    print("\nã€æœ€è‰¯æ‰‹æ³•ã¨ãªã£ãŸå›æ•°ã€‘")
    best_count = {"MeCabè¤‡åˆåè©": 0, "æ­£è¦è¡¨ç¾": 0, "çµ±åˆç‰ˆ": 0}
    for case_name, case_results in all_results.items():
        best = max(case_results.items(),
                  key=lambda x: x[1]['metrics']['ç·åˆã‚¹ã‚³ã‚¢'])
        if best[0] in best_count:
            best_count[best[0]] += 1

    for method, count in best_count.items():
        percentage = count / len(test_cases) * 100
        print(f"  {method}: {count}å› ({percentage:.1f}%)")

    # ã‚±ãƒ¼ã‚¹åˆ¥ã®å„ªä½æ€§åˆ†æ
    print("\nã€ã‚±ãƒ¼ã‚¹åˆ¥å„ªä½æ€§ã€‘")
    for case_name, case_results in all_results.items():
        scores = {method: results['metrics']['ç·åˆã‚¹ã‚³ã‚¢']
                 for method, results in case_results.items()}
        best = max(scores.items(), key=lambda x: x[1])
        print(f"  {case_name:15s}: {best[0]} (ã‚¹ã‚³ã‚¢å·®: {best[1] - min(scores.values()):.3f})")

    # çµ±åˆç‰ˆã®ç›¸å¯¾çš„å„ªä½æ€§
    print("\nã€çµ±åˆç‰ˆã®ç›¸å¯¾çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
    integrated_advantages = []
    for case_name, case_results in all_results.items():
        if 'çµ±åˆç‰ˆ' in case_results:
            integrated_score = case_results['çµ±åˆç‰ˆ']['metrics']['ç·åˆã‚¹ã‚³ã‚¢']
            other_scores = [r['metrics']['ç·åˆã‚¹ã‚³ã‚¢']
                          for m, r in case_results.items() if m != 'çµ±åˆç‰ˆ']
            if other_scores:
                advantage = integrated_score - max(other_scores)
                integrated_advantages.append(advantage)
                if advantage > 0:
                    print(f"  {case_name}: +{advantage:.3f} (å„ªä½)")
                elif advantage < 0:
                    print(f"  {case_name}: {advantage:.3f} (åŠ£ä½)")
                else:
                    print(f"  {case_name}: Â±0.000 (åŒç­‰)")

    if integrated_advantages:
        avg_advantage = sum(integrated_advantages) / len(integrated_advantages)
        print(f"\n  çµ±åˆç‰ˆã®å¹³å‡å„ªä½æ€§: {avg_advantage:+.3f}")
        if avg_advantage > 0:
            print("  â†’ çµ±åˆç‰ˆã¯å¹³å‡çš„ã«ä»–æ‰‹æ³•ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹")
        elif avg_advantage < 0:
            print("  â†’ çµ±åˆç‰ˆã¯å¹³å‡çš„ã«ä»–æ‰‹æ³•ã‚ˆã‚ŠåŠ£ã‚‹")
        else:
            print("  â†’ çµ±åˆç‰ˆã¯ä»–æ‰‹æ³•ã¨åŒç­‰")

    # çµè«–
    print("\n" + "=" * 100)
    print("è©•ä¾¡çµè«–")
    print("=" * 100)

    # æœ€é«˜å¹³å‡ã‚¹ã‚³ã‚¢ã®æ‰‹æ³•
    if avg_scores:
        best_avg_method = max(avg_scores.items(), key=lambda x: x[1])
        print(f"\nğŸ“Š æœ€é«˜å¹³å‡ã‚¹ã‚³ã‚¢: {best_avg_method[0]} ({best_avg_method[1]:.3f})")

    # æœ€å¤šå‹åˆ©ã®æ‰‹æ³•
    if best_count:
        most_wins = max(best_count.items(), key=lambda x: x[1])
        print(f"ğŸ… æœ€å¤šå‹åˆ©: {most_wins[0]} ({most_wins[1]}å›)")

    # çµ±åˆç‰ˆã®è©•ä¾¡
    if 'çµ±åˆç‰ˆ' in avg_scores:
        integrated_rank = sorted(avg_scores.values(), reverse=True).index(avg_scores['çµ±åˆç‰ˆ']) + 1
        print(f"\nçµ±åˆç‰ˆã®é †ä½: {integrated_rank}ä½ / {len(avg_scores)}æ‰‹æ³•ä¸­")

        # çµ±åˆç‰ˆãŒå„ªä½ãªã‚±ãƒ¼ã‚¹
        integrated_best_cases = [case for case, results in all_results.items()
                                if 'çµ±åˆç‰ˆ' in results and
                                max(results.items(), key=lambda x: x[1]['metrics']['ç·åˆã‚¹ã‚³ã‚¢'])[0] == 'çµ±åˆç‰ˆ']
        if integrated_best_cases:
            print(f"\nçµ±åˆç‰ˆãŒæœ€è‰¯ã®ã‚±ãƒ¼ã‚¹:")
            for case in integrated_best_cases:
                print(f"  â€¢ {case}")


if __name__ == "__main__":
    run_comprehensive_evaluation()